

import asyncio
import json
import nest_asyncio
from tabulate import tabulate
from mcp import ClientSession
from mcp.client.sse import sse_client
from langgraph.graph import StateGraph
from langchain.chat_models import AzureChatOpenAI

nest_asyncio.apply()

# === Azure OpenAI Client ===
def get_openai_client():
    return AzureChatOpenAI(
        azure_deployment="Fourth_Chatbot",
        azure_endpoint="https://testopenaiassets.openai.azure.com",
        openai_api_version="2024-08-01-preview",
        openai_api_key="",  # Set via environment securely
        temperature=0.7,
        max_tokens=2000,
        model_kwargs={"top_p": 0.9, "frequency_penalty": 0.2, "presence_penalty": 0.1}
    )

# === SSE URL ===
sse_url = "https://employee-mcp-v1-6b0n6.dw4w1g-2.gbr-e1.cloudhub.io/sse"

# === Sync Tool Fetch ===
def sync_fetch_tools():
    async def fetch():
        async with sse_client(url=sse_url) as streams:
            async with ClientSession(*streams) as session:
                await session.initialize()
                return await session.list_tools()
    return asyncio.get_event_loop().run_until_complete(fetch())

# === Sync Tool Execution ===
def sync_call_tool(tool_name: str, tool_input: dict):
    async def call():
        async with sse_client(url=sse_url) as streams:
            async with ClientSession(*streams) as session:
                await session.initialize()
                return await session.call_tool(tool_name, tool_input)
    try:
        return asyncio.get_event_loop().run_until_complete(call())
    except Exception as e:
        return f"[ERROR] {e}"

# === LLM Utility Functions ===
def extract_entities(user_input: str, entity_type: str = "projects") -> list:
    llm = get_openai_client()
    prompt = f"""Extract a list of {entity_type} mentioned in the user query:
Query: "{user_input}"
Return a JSON list like ["project1", "project2", ...]"""
    try:
        response = llm.invoke(prompt).content
        return json.loads(response)
    except Exception as e:
        print("[Entity Extract Error]", e)
        return []

def extract_input(user_input: str, tool_name: str, schema: dict, context: dict) -> dict:
    llm = get_openai_client()
    schema_str = "\n".join(f"- {k}: {v}" for k, v in schema.get("properties", {}).items())
    context_str = ", ".join(f"{k}={v}" for k, v in context.items())
    prompt = f"""Based on the user query: "{user_input}" and context: {context_str},
and the input schema of {tool_name}:

{schema_str}

Generate a valid JSON input for the tool."""
    try:
        response = llm.invoke(prompt).content
        return json.loads(response)
    except Exception as e:
        print("Input extraction failed:", e)
        return {}

# === Main Node Logic ===
def plan_and_execute(state: dict) -> dict:
    tools = state.get("available_tools", [])
    user_input = state.get("user_input", "")
    all_results = []

    # Step 1: Extract all projects from input
    project_names = extract_entities(user_input, entity_type="projects")

    for project in project_names:
        context = {"project": project}

        # Step 2: Choose tools using LLM
        tool_selector = get_openai_client()
        tool_list = "\n".join([f"{t['name']}: {t['description']}" for t in tools])
        plan_prompt = f"""You're given this user query: "{user_input}" for project: "{project}"

Available tools:
{tool_list}

Return a JSON list of tool names (like ["GetProjects", "GetProjectEmployees", ...])
required to fulfill this request.
Only return the list."""
        try:
            plan_response = tool_selector.invoke(plan_prompt).content
            tool_names = json.loads(plan_response)
        except Exception as e:
            print("[Plan Failed]", e)
            continue

        # Step 3: For each tool, extract input and invoke
        for tool_name in tool_names:
            tool = next((t for t in tools if t["name"] == tool_name), None)
            if not tool:
                continue

            tool_input = extract_input(user_input, tool_name, tool["inputSchema"], context)
            result = sync_call_tool(tool_name, tool_input)

            # Extract content and convert to JSON if possible
            if hasattr(result, "content"):
                for part in result.content:
                    if hasattr(part, "text"):
                        try:
                            parsed = json.loads(part.text)
                            if isinstance(parsed, list):
                                all_results.extend(parsed)
                            elif isinstance(parsed, dict):
                                all_results.append(parsed)
                            break
                        except Exception:
                            continue

    # === Merge All Results ===
    if all_results:
        unique_fields = set()
        for row in all_results:
            unique_fields.update(row.keys())
        merged_headers = list(unique_fields)
        rows = [[row.get(col, "") for col in merged_headers] for row in all_results]
        table = tabulate(rows, headers=merged_headers, tablefmt="grid")
        return {"result": table}

    return {"result": "[INFO] No data found for requested projects."}

# === Fallback Node ===
def fallback_node(state: dict) -> dict:
    return {"result": "[ERROR] Something went wrong during execution."}

# === Graph Builder ===
def build_graph():
    graph = StateGraph(dict)
    graph.add_node("list_tools", list_tools_node)
    graph.add_node("plan_and_execute", plan_and_execute)
    graph.add_node("default", fallback_node)

    graph.add_conditional_edges("list_tools", lambda s: s["__next__"], {
        "plan_and_execute": "plan_and_execute"
    })

    graph.set_entry_point("list_tools")
    return graph.compile()

# === Initial Tool Fetch ===
def list_tools_node(state: dict) -> dict:
    try:
        result = sync_fetch_tools()
        tools = [{
            "name": t.name,
            "description": t.description,
            "inputSchema": t.inputSchema
        } for t in getattr(result, "tools", [])]
        state["available_tools"] = tools
        state["__next__"] = "plan_and_execute"
        return state
    except Exception as e:
        return {"result": f"[ERROR] Failed to fetch tools: {e}"}

# === CLI Driver ===
if __name__ == "__main__":
    initial_state = {}
    tool_state = list_tools_node(initial_state)

    if "available_tools" not in tool_state:
        print(tool_state.get("result", "[ERROR] Could not load tools."))
        exit()

    print("\nAvailable Tools:")
    for t in tool_state["available_tools"]:
        print(f"- {t['name']}: {t['description']}")

    user_input = input("\nDescribe what you want: ")
    tool_state["user_input"] = user_input

    runnable = build_graph()
    result = runnable.invoke(tool_state)

    print("\nOutput:\n", result.get("result", "No result returned."))
