import os
import json
import logging
import random
import string
from base64 import b64decode

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ========== DUMMY VALUE GENERATOR ==========

def generate_dummy_value(value):
    if isinstance(value, bool):
        return random.choice([True, False])
    elif isinstance(value, int):
        return random.randint(1000, 9999)
    elif isinstance(value, float):
        return round(random.uniform(10.0, 9999.99), 2)
    elif isinstance(value, str):
        return ''.join(random.choices(string.ascii_letters + string.digits, k=8))
    elif isinstance(value, list):
        return [generate_dummy_value(value[0]) if value else "example"] * random.randint(1, 3)
    elif isinstance(value, dict):
        return {k: generate_dummy_value(v) for k, v in value.items()}
    else:
        return "dummy"

# ========== JSON PARSING FROM RAML ==========

def extract_json_blocks(raml_text):
    """
    Extract JSON payload blocks from RAML text.
    Looks for lines under `example:` or `application/json:` that are JSON.
    """
    json_blocks = {}
    current_endpoint = None
    capture = False
    buffer = []

    lines = raml_text.splitlines()
    for i, line in enumerate(lines):
        stripped = line.strip()

        if stripped.startswith("/"):
            current_endpoint = stripped
            capture = False
            buffer = []

        if "application/json" in stripped or "example:" in stripped:
            capture = True
            buffer = []
            continue

        if capture:
            if stripped == "":
                continue
            buffer.append(line)
            # Check if weâ€™ve finished the JSON block (next endpoint or end of file)
            next_lines = lines[i+1:i+4]
            if any(l.strip().startswith("/") for l in next_lines) or i == len(lines) - 1:
                full_json = '\n'.join(buffer)
                try:
                    # Try to find JSON object starting with {
                    json_start = full_json.find('{')
                    json_data = json.loads(full_json[json_start:])
                    if current_endpoint:
                        json_blocks[current_endpoint] = json_data
                except Exception as e:
                    logger.warning(f"Failed to parse JSON for {current_endpoint}: {e}")
                capture = False

    return json_blocks

# ========== PAYLOAD GENERATION ==========

def generate_random_payloads(json_blocks):
    output = {}
    for endpoint, original_payload in json_blocks.items():
        output[endpoint] = [
            generate_dummy_value(original_payload),
            generate_dummy_value(original_payload)
        ]
    return output

# ========== MOCK OPENAI WRAPPER ==========

def mock_openai_client(model_instance_name):
    class MockClient:
        def invoke(self, messages):
            raml_content = messages[0]['content']
            json_blocks = extract_json_blocks(raml_content)
            randomized_payloads = generate_random_payloads(json_blocks)
            return type('obj', (object,), {'content': json.dumps(randomized_payloads)})
    return MockClient()

# ========== OPENAI WRAPPER FUNCTION ==========

def analyze_raml_with_openai(client, raml_content):
    try:
        prompt = (
            "Analyze the RAML file and extract all JSON example blocks. "
            "Preserve all field names and structure, but generate two randomized test payloads per endpoint. "
        )
        response = client.invoke([{"content": prompt + "\n\n" + raml_content}])
        return response.content
    except Exception as e:
        logger.error(f"OpenAI processing error: {e}")
        raise

# ========== MAIN LAMBDA HANDLER ==========

def lambda_handler(event, context):
    logger.info("Lambda invoked.")
    try:
        if 'body' not in event or not event.get('isBase64Encoded', False):
            raise ValueError("RAML file not found or not base64-encoded.")

        raml_bytes = b64decode(event['body'])
        raml_content = raml_bytes.decode('utf-8', errors='ignore')

        headers = event.get('headers', {})
        model_instance_name = (
            headers.get('model_instance_name') or
            headers.get('Model_Instance_Name') or
            os.environ.get('DEFAULT_MODEL_INSTANCE_NAME', 'default-model')
        )

        client = mock_openai_client(model_instance_name)
        result = analyze_raml_with_openai(client, raml_content)

        return {
            "statusCode": 200,
            "headers": {"Content-Type": "application/json"},
            "body": result
        }

    except Exception as e:
        logger.error(f"Processing error: {e}")
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }
