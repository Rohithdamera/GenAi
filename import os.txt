import os
import json
import random
import string
import logging
from base64 import b64decode

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def random_string(length=8):
    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))

def random_int():
    return random.randint(1, 1000)

def random_boolean():
    return random.choice([True, False])

def generate_random_value(value_type):
    if value_type == 'string':
        return random_string()
    elif value_type == 'int':
        return random_int()
    elif value_type == 'boolean':
        return random_boolean()
    else:
        return None

def fill_empty_values(obj):
    # Randomizes values based on field types (string, int, boolean)
    if isinstance(obj, dict):
        return {k: generate_random_value(v) if v != "" else None for k, v in obj.items()}
    elif isinstance(obj, list):
        return [fill_empty_values(i) for i in obj]
    return obj

def mock_openai_client(model_instance_name):
    class MockClient:
        def invoke(self, messages):
            raml_content = messages[0]['content']
            endpoints = extract_endpoints_from_raml(raml_content)
            payloads = generate_payloads_for_endpoints(endpoints, raml_content)
            payloads = fill_empty_values(payloads)
            return type('obj', (object,), {'content': json.dumps(payloads)})

    return MockClient()

def extract_endpoints_from_raml(raml_content):
    endpoints = []
    lines = raml_content.split('\n')
    for line in lines:
        if line.startswith('/'):
            endpoints.append(line.strip())
    return endpoints

def generate_payloads_for_endpoints(endpoints, raml_content):
    payloads = {}
    for endpoint in endpoints:
        payloads[endpoint] = extract_fields_for_endpoint(endpoint, raml_content)
    return payloads

def extract_fields_for_endpoint(endpoint, raml_content):
    fields = {}
    lines = raml_content.split('\n')
    capture = False
    for line in lines:
        if line.strip() == endpoint:
            capture = True
        elif capture and line.startswith('/'):
            break
        elif capture:
            parts = line.split(':')
            if len(parts) == 2:
                key = parts[0].strip()
                value_type = parts[1].strip().lower()  # Assuming field type is defined after the colon
                fields[key] = value_type  # Store the field type
    return fields

def resolve_includes_in_raml(file_path):
    resolved_lines = []
    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
        for line in file:
            resolved_lines.append(line.rstrip())

    return "\n".join(resolved_lines)

def analyze_raml_with_openai(client, resolved_raml_content):
    try:
        prompt = (
            "You are an expert RAML analyzer. Analyze the following RAML content, "
            "resolve all included files, traits, resource types, and fragments, "
            "and then generate meaningful and valid test payloads for each endpoint defined. "
            "Ensure that the payload fields are complete and contain realistic example values. "
            "Respond only with a JSON containing the endpoints and their payloads. "
            "Please randomize all values while keeping field names intact."
        )
        response = client.invoke([{"content": prompt + "\n\n" + resolved_raml_content}])
        return response.content
    except Exception as e:
        logger.error(f"Error analyzing RAML with OpenAI: {e}")
        raise ValueError(f"Error analyzing RAML with OpenAI: {e}")

def lambda_handler(event, context):
    logger.info("Lambda invoked.")
    try:
        if 'body' not in event or not event.get('isBase64Encoded', False):
            raise ValueError("File content is missing or not base64-encoded.")

        raml_bytes = b64decode(event['body'])

        headers = event.get('headers', {})
        model_instance_name = (
            headers.get('model_instance_name') or
            headers.get('Model_Instance_Name') or
            os.environ.get('DEFAULT_MODEL_INSTANCE_NAME', 'default-model')
        )

        raml_content = raml_bytes.decode('utf-8')
        resolved_raml = resolve_includes_in_raml(raml_content)

        client = mock_openai_client(model_instance_name)
        final_output = analyze_raml_with_openai(client, resolved_raml)

        return {
            "statusCode": 200,
            "headers": {"Content-Type": "application/json"},
            "body": final_output
        }

    except Exception as e:
        logger.error(f"Error during execution: {e}")
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }
