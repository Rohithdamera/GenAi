import gradio as gr
import mysql.connector
import json
from langchain_openai import AzureChatOpenAI
from langchain.callbacks import get_openai_callback
from langchain.callbacks.base import ConsoleCallbackHandler


# -------------------------------
# Configure Azure OpenAI
# -------------------------------
llm = AzureChatOpenAI(
    deployment_name="gpt-4_complex_conversions",
    azure_endpoint="https://testopenaiassets.openai.azure.com",
    openai_api_key="",  # <-- Put your API Key here
    openai_api_version="2025-01-01-preview"
)


# -------------------------------
# Configure MySQL
# -------------------------------
config = {
    "host": "localhost",
    "user": "root",        # your MySQL user
    "password": "Admin",   # your MySQL password
    "database": "test_data"
}


def fetch_logs():
    """Fetch logs or API performance data from MySQL."""
    conn = mysql.connector.connect(**config)
    cursor = conn.cursor(dictionary=True)

    cursor.execute("SELECT * FROM api_logs LIMIT 50")  # adjust table & query as needed
    results = cursor.fetchall()

    cursor.close()
    conn.close()
    return results


# -------------------------------
# Chat Function
# -------------------------------
def chat_with_agent(user_prompt):
    try:
        # Fetch logs from DB
        results = fetch_logs()
        results_str = json.dumps(results, indent=2)

        # Construct final prompt for LLM
        messages = [
            {
                "role": "system",
                "content": (
                    "You are a senior data analyst. Analyze API/system logs. "
                    "Answer questions like 'how many debugs happened' or "
                    "'what errors are present in the logs'. "
                    "Be concise and structured in your response."
                ),
            },
            {
                "role": "user",
                "content": f"{user_prompt}\n\nHere are the logs:\n{results_str}"
            },
        ]

        # Call Azure LLM with callback to track token usage
        with get_openai_callback() as cb:
            result = llm.invoke(messages, config={"callbacks": [ConsoleCallbackHandler()]})
            final_response = result.content

            # Append token usage details
            final_response += "\n\n--- Token Usage ---"
            final_response += f"\nTotal Tokens: {cb.total_tokens}"
            final_response += f"\nPrompt Tokens: {cb.prompt_tokens}"
            final_response += f"\nCompletion Tokens: {cb.completion_tokens}"
            final_response += f"\nTotal Cost (USD): ${format(cb.total_cost, '.6f')}"

        return final_response

    except Exception as e:
        return f"❌ Error: {str(e)}"


# -------------------------------
# Gradio UI
# -------------------------------
chatbot_ui = gr.ChatInterface(
    fn=chat_with_agent,
    title="OSIF Co-Developer",
    description="Query system/API logs with natural language",
    theme="default"
)

# Launch UI
if __name__ == "__main__":
    chatbot_ui.launch(debug=False)