import os
import logging
import json
import re
from base64 import b64decode
from Crypto.Cipher import AES
from Crypto.Util.Padding import unpad
from langchain_community.chat_models import AzureChatOpenAI
from langchain.schema import HumanMessage
import tempfile
import openpyxl
from openpyxl.utils import column_index_from_string

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger()

# AES Decryption
def decrypt(data, key):
    cipher = AES.new(b64decode(key), AES.MODE_ECB)
    decrypted_data = cipher.decrypt(b64decode(data))
    decrypted_data = unpad(decrypted_data, AES.block_size)
    return decrypted_data.decode()

# Azure OpenAI Client
def get_openai_client(model_instance_name):
    aes_key_base64 = os.environ['AES_KEY']
    encrypted_api_base = os.environ['ENCRYPTED_API_BASE']
    encrypted_api_key = os.environ['ENCRYPTED_API_KEY']
    api_version = os.environ['AZURE_API_VERSION']

    decrypted_api_base = decrypt(encrypted_api_base, aes_key_base64)
    decrypted_api_key = decrypt(encrypted_api_key, aes_key_base64)

    if not decrypted_api_base.endswith('/'):
        decrypted_api_base += '/'

    return AzureChatOpenAI(
        deployment_name=model_instance_name,
        openai_api_base=decrypted_api_base,
        openai_api_key=decrypted_api_key,
        openai_api_version=api_version,
        temperature=0.4,
        max_tokens=4096
    )

def col_letter_to_index(letter):
    return column_index_from_string(letter.upper()) - 1

# Extract {key(value)} metadata from prompt
def extract_metadata_from_prompt(prompt):
    def extract(key):
        match = re.search(r'\{' + re.escape(key) + r'\(([^)]+)\)\}', prompt)
        return match.group(1).strip() if match else None

    sheet_name = extract("sheet_name")
    source_col = extract("source_system_column")
    target_col = extract("target_system_column")
    logic_col = extract("business_logic_column")

    if not all([sheet_name, source_col, target_col, logic_col]):
        raise ValueError("Prompt must include {sheet_name()}, {source_system_column()}, {target_system_column()}, {business_logic_column()}")

    return {
        "sheet_name": sheet_name,
        "source_col": col_letter_to_index(source_col),
        "target_col": col_letter_to_index(target_col),
        "logic_col": col_letter_to_index(logic_col)
    }

# Extract limited rows from Excel for safe prompt size
def extract_excel_data(file_path, sheet_name, source_col, logic_col, target_col, max_rows=50):
    try:
        wb = openpyxl.load_workbook(file_path, data_only=True)
        sheet = wb[sheet_name]
        data = []
        for i, row in enumerate(sheet.iter_rows(min_row=2, values_only=True)):
            if i >= max_rows:
                break
            source = row[source_col]
            logic = row[logic_col]
            target = row[target_col]
            if source and target:
                data.append({
                    "source": str(source),
                    "logic": str(logic or ""),
                    "target": str(target)
                })
        return data
    except Exception as e:
        logger.error(f"Excel processing error: {e}")
        raise

# Build safe prompt
def build_prompt(instruction, prompt_intro, extracted_data):
    prompt = instruction.strip() + "\n\n" + prompt_intro.strip()
    prompt += "\n\nExtracted Sample Data (first 50 rows):\n"
    for row in extracted_data:
        prompt += f"- Source: {row['source']}, Target: {row['target']}, Logic: {row['logic']}\n"
    return prompt

# Lambda handler
def lambda_handler(event, context):
    try:
        headers = event.get("headers", {}) or {}
        model_instance = headers.get("model_instance_name", "")
        query = event.get("queryStringParameters", {}) or {}

        instruction = query.get("instruction", "")
        prompt_text = query.get("prompt", "")

        if not instruction or not prompt_text:
            raise ValueError("Missing required query params: instruction or prompt")

        if not event.get("isBase64Encoded", False):
            raise ValueError("Expected base64-encoded binary file")

        file_b64 = event.get("body", "")
        if not file_b64:
            raise ValueError("No file body found")

        # Decode and save uploaded Excel
        body = b64decode(file_b64)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as temp_file:
            temp_file.write(body)
            file_path = temp_file.name

        # Extract metadata and Excel data
        metadata = extract_metadata_from_prompt(prompt_text)
        extracted_data = extract_excel_data(
            file_path,
            metadata["sheet_name"],
            metadata["source_col"],
            metadata["logic_col"],
            metadata["target_col"],
            max_rows=50
        )

        full_prompt = build_prompt(instruction, prompt_text, extracted_data)
        logger.info(f"Final prompt size: {len(full_prompt)} characters")

        client = get_openai_client(model_instance)
        response = client.invoke([
            HumanMessage(content=full_prompt),
            HumanMessage(content="Generate the DataWeave script.")
        ])

        return {
            "statusCode": 200,
            "headers": {"Content-Type": "text/plain"},
            "body": response.content.strip()
        }

    except Exception as e:
        logger.error(f"Error occurred: {e}")
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }
