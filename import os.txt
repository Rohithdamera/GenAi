import os
import logging
import json
from base64 import b64decode
from Crypto.Cipher import AES
from langchain_community.chat_models import AzureChatOpenAI
from langchain.schema import HumanMessage

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def unpad(data):
    """Remove padding from decrypted data."""
    padding_length = data[-1]
    return data[:-padding_length]

def decrypt(data, key):
    """Decrypt the data using AES and remove padding."""
    cipher = AES.new(b64decode(key), AES.MODE_ECB)
    decrypted_data = cipher.decrypt(b64decode(data))
    decrypted_data = unpad(decrypted_data)
    return decrypted_data.decode()

def get_openai_client(agent_name, model_instance_name):
    """Initialize Azure OpenAI client using decrypted API credentials."""
    try:
        # Fetch and decrypt necessary environment variables
        aes_key_base64 = os.environ['AES_KEY']
        encrypted_api_base = os.environ['ENCRYPTED_API_BASE']
        encrypted_api_key = os.environ['ENCRYPTED_API_KEY']
        api_version = os.environ['AZURE_API_VERSION']

        decrypted_api_base = decrypt(encrypted_api_base, aes_key_base64)
        decrypted_api_key = decrypt(encrypted_api_key, aes_key_base64)

        # Ensure the base URL ends with a slash
        if not decrypted_api_base.endswith('/'):
            decrypted_api_base += '/'

        # Construct the request URL
        request_url = f"{decrypted_api_base}openai/deployments/{model_instance_name}/chat/completions?api-version={api_version}"
        logger.info(f"Constructed Request URL: {request_url}")

        # Return the AzureChatOpenAI client initialized with the decrypted details
        return AzureChatOpenAI(
            deployment_name=model_instance_name,
            openai_api_base=decrypted_api_base,
            openai_api_key=decrypted_api_key,
            openai_api_version=api_version
        )
    except Exception as e:
        logger.error(f"Error initializing OpenAI client: {e}")
        raise ValueError(f"Error initializing OpenAI client: {e}")

def process_with_openai(client, file_content, agent_name):
    """Process file content using OpenAI based on Agent_name."""
    try:
        # Customize the prompt based on agent_name
        if agent_name == "xslt_to_dwl":
            prompt = (
                "You are an expert in Mulesoft integration. I will provide XSLT code. "
                "Please convert it into an equivalent DataWeave (DWL 2.0) script that performs the same transformation. "
                "Ensure that the output script is clean, properly formatted, and complete. "
                "Use appropriate DataWeave functions and syntax to mimic the logic of the original XSLT."
            )
        else:
            raise ValueError(f"Unsupported Agent_name: {agent_name}")

        # Make the request to OpenAI
        response = client.invoke([HumanMessage(content=prompt + "\n\n" + file_content)])
        return response.content
    except Exception as e:
        logger.error(f"Error in OpenAI API call: {e}")
        raise

def process_file_content(agent_name, file_content, model_instance_name):
    """Process the DataWeave script based on the agent name."""
    try:
        client = get_openai_client(agent_name, model_instance_name)
        result = process_with_openai(client, file_content, agent_name)
        return result
    except Exception as e:
        logger.error(f"Error processing file content: {e}")
        raise

def lambda_handler(event, context):
    """AWS Lambda entry point."""
    logger.info(f"Received event: {json.dumps(event)}")

    try:
        # Validate base64 encoded file content in the event
        if 'body' not in event or not event.get('isBase64Encoded', False):
            raise ValueError("File content is missing or not base64-encoded in the event.")

        # Decode the base64 file content as binary
        try:
            file_content = b64decode(event['body'])  # Treat the file content as binary
        except Exception as e:
            raise ValueError(f"Failed to decode file content: {e}")

        # Extract query parameters (Agent_name)
        query_params = event.get('queryStringParameters', {})
        agent_name = query_params.get('Agent_name')
        if not agent_name:
            raise ValueError("'Agent_name' is missing in the query parameters.")

        # Extract model_instance_name from headers
        model_instance_name = event.get('headers', {}).get('model_instance_name')
        if not model_instance_name:
            raise ValueError("'model_instance_name' is missing in the headers.")

        # Process the file content using OpenAI and the agent name
        processed_result = process_file_content(agent_name, file_content, model_instance_name)

        # Return the processed result based on agent_name
        if agent_name == "xslt_to_dwl":
            return {
                "statusCode": 200,
                "headers": {"Content-Type": "text/plain"},
                "body": processed_result
            }
        else:
            raise ValueError("Unsupported Agent_name specified.")

    except Exception as e:
        logger.error(f"An error occurred: {e}")
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }
