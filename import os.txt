import os
import json
import logging
import traceback
import random
import string
from base64 import b64decode
from Crypto.Cipher import AES
from langchain_community.chat_models import AzureChatOpenAI
from langchain.schema import HumanMessage

# Setup logger
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# AES decryption
def unpad(data):
    return data[:-data[-1]]

def decrypt(data, key):
    cipher = AES.new(b64decode(key), AES.MODE_ECB)
    decrypted_data = cipher.decrypt(b64decode(data))
    return unpad(decrypted_data).decode()

# OpenAI client setup
def get_openai_client(model_instance_name):
    aes_key = os.environ['AES_KEY']
    api_base = decrypt(os.environ['ENCRYPTED_API_BASE'], aes_key)
    api_key = decrypt(os.environ['ENCRYPTED_API_KEY'], aes_key)
    api_version = os.environ['AZURE_API_VERSION']

    if not api_base.endswith("/"):
        api_base += "/"

    logger.info(f"Using OpenAI endpoint: {api_base}openai/deployments/{model_instance_name}/chat/completions?api-version={api_version}")

    return AzureChatOpenAI(
        deployment_name=model_instance_name,
        openai_api_base=api_base,
        openai_api_key=api_key,
        openai_api_version=api_version
    )

# Prompt generator
def get_prompt(file_content, user_input, iteration=None, total=None):
    return f"""
You are an expert in analysing the RAML and generating the payload from the RAML. I am providing the RAML which will be used as an asset for designing my API. Please anlayze the RAML and generate the sample payload which will honour all the rules inside the RAML. You can refer the link for any doubts related to RAML:
https://raml.org/developers/raml-100-tutorial

Please generate the payloads for all the endpoints in the RAML. Use the input "{user_input}" to understand where the request should be targeted.

This is sample {iteration+1} of {total}. Ensure this sample is different from others. Vary string contents, numbers, and date values randomly.

Here is the RAML file content:
{file_content}

Only return valid JSON. No explanation, no text.
""".strip()

# Parse GPT output
def parse_response_as_json(response_content):
    try:
        return json.loads(response_content)
    except json.JSONDecodeError:
        cleaned = response_content.strip()
        if cleaned.startswith("```json"):
            cleaned = cleaned.replace("```json", "").replace("```", "").strip()
        return json.loads(cleaned)

# Generate payloads
def generate_payloads(client, file_content, user_input, count):
    results = []
    for i in range(count):
        prompt = get_prompt(file_content, user_input, i, count)
        response = client.invoke([HumanMessage(content=prompt)])
        try:
            parsed = parse_response_as_json(response.content)
            results.append(parsed)
        except Exception as e:
            logger.error(f"Failed to parse JSON from model response: {response.content}")
            raise
    return results if count > 1 else results[0]

# Lambda entry
def lambda_handler(event, context):
    try:
        logger.info(f"Incoming event: {json.dumps(event)[:500]}")

        if 'body' not in event or not event.get('isBase64Encoded', False):
            raise ValueError("Missing or invalid base64-encoded file content.")

        file_content = b64decode(event['body']).decode('utf-8')
        headers = event.get('headers', {}) or {}
        params = event.get('queryStringParameters', {}) or {}

        model_instance_name = headers.get('model_instance_name')
        if not model_instance_name:
            raise ValueError("Missing 'model_instance_name' in headers.")

        user_input = params.get('input', '/default')
        count = int(headers.get('count', 1))

        client = get_openai_client(model_instance_name)
        result = generate_payloads(client, file_content, user_input, count)

        return {
            "statusCode": 200,
            "headers": {"Content-Type": "application/json"},
            "body": json.dumps(result, indent=2)
        }

    except Exception as e:
        logger.error("Error occurred:")
        logger.error(traceback.format_exc())
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }
