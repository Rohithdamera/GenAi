import logging
import os
import json
import re
from base64 import b64decode
from Crypto.Cipher import AES
from azure.functions import HttpRequest, HttpResponse
from langchain_community.chat_models import AzureChatOpenAI
from langchain.schema import HumanMessage

logger = logging.getLogger("azure.functions")
logger.setLevel(logging.INFO)

def unpad(data):
    padding_length = data[-1]
    return data[:-padding_length]

def decrypt(data, key):
    cipher = AES.new(b64decode(key), AES.MODE_ECB)
    decrypted_data = cipher.decrypt(b64decode(data))
    decrypted_data = unpad(decrypted_data)
    return decrypted_data.decode()

def get_openai_client(model_instance_name):
    aes_key_base64 = os.environ["AES_KEY"]
    encrypted_api_base = os.environ["ENCRYPTED_API_BASE"]
    encrypted_api_key = os.environ["ENCRYPTED_API_KEY"]
    api_version = os.environ["AZURE_API_VERSION"]

    decrypted_api_base = decrypt(encrypted_api_base, aes_key_base64)
    decrypted_api_key = decrypt(encrypted_api_key, aes_key_base64)

    if not decrypted_api_base.endswith('/'):
        decrypted_api_base += '/'

    return AzureChatOpenAI(
        deployment_name=model_instance_name,
        openai_api_base=decrypted_api_base,
        openai_api_key=decrypted_api_key,
        openai_api_version=api_version
    )

def detect_file_type(file_content):
    if re.search(r"^(%RAML)|(^#%RAML)", file_content.strip(), re.IGNORECASE):
        return "raml"
    elif "<xs:schema" in file_content or "http://www.w3.org/2001/XMLSchema" in file_content:
        return "xsd"
    return "unknown"

def get_instruction_and_prompt(input_type, custom_prompt=None):
    if input_type == "/sampleforraml":
        instruction = (
            "You are an expert in analysing the RAML and generating the payload from the RAML. "
            "Please analyze the RAML and generate the sample payload which will honor all the rules. "
            "Only return a valid JSON object or JSON array. Do NOT include markdown or extra text."
        )
        default_prompt = "Please generate one JSON payload from the following RAML:"
        content_type = "application/json"
    elif input_type == "/sampleforxsd":
        instruction = (
            "You are an expert in analysing the XSD and generating the payload from the XSD. "
            "Please analyze the XSD and generate the sample payload which will honor all the rules. "
            "Only return XML output. Do NOT include markdown or extra text."
        )
        default_prompt = "Please generate one XML payload for the following XSD:"
        content_type = "application/xml"
    else:
        raise ValueError("Unsupported input type")

    return {
        "instruction": instruction,
        "prompt": custom_prompt or default_prompt,
        "content_type": content_type
    }

def extract_json_from_response(text):
    try:
        return json.loads(text)
    except:
        pass

    json_matches = re.findall(r"```json(.*?)```", text, re.DOTALL | re.IGNORECASE)
    for match in json_matches:
        try:
            return json.loads(match.strip())
        except:
            continue

    obj_match = re.search(r"(\{.*\})", text, re.DOTALL)
    if obj_match:
        try:
            return json.loads(obj_match.group(1))
        except:
            pass

    arr_match = re.search(r"(\[.*\])", text, re.DOTALL)
    if arr_match:
        try:
            return json.loads(arr_match.group(1))
        except:
            pass

    return None

def main(req: HttpRequest) -> HttpResponse:
    try:
        input_value = req.params.get("input")
        custom_prompt = req.params.get("prompt")

        if not input_value:
            return HttpResponse(json.dumps({"error": "'input' parameter is missing"}), status_code=400)

        model_instance_name = req.headers.get("model_instance_name")
        if not model_instance_name:
            return HttpResponse(json.dumps({"error": "'model_instance_name' header is missing"}), status_code=400)

        count = int(req.headers.get("count", "1"))

        file_content = req.get_body().decode("utf-8")
        file_type = detect_file_type(file_content)

        if input_value == "/sampleforraml" and file_type != "raml":
            return HttpResponse(json.dumps({"error": "Only RAML or RAML-like .txt content is allowed"}), status_code=400)
        if input_value == "/sampleforxsd" and file_type != "xsd":
            return HttpResponse(json.dumps({"error": "Only XSD or XSD-like .txt content is allowed"}), status_code=400)

        prompt_data = get_instruction_and_prompt(input_value, custom_prompt)
        client = get_openai_client(model_instance_name)

        results = []
        for i in range(count):
            message = [
                HumanMessage(content=prompt_data["instruction"]),
                HumanMessage(content=prompt_data["prompt"] + "\n\n" + file_content)
            ]
            response = client.invoke(message)

            if input_value == "/sampleforraml":
                parsed = extract_json_from_response(response.content.strip())
                if parsed is not None:
                    results.append(parsed)
                else:
                    logger.warning(f"Failed to parse JSON from response {i+1}")
            else:
                results.append(response.content.strip())

        if input_value == "/sampleforraml":
            return HttpResponse(json.dumps(results, indent=2), mimetype=prompt_data["content_type"])
        else:
            return HttpResponse("\n\n".join(results), mimetype=prompt_data["content_type"])

    except Exception as e:
        logger.exception("Error processing request")
        return HttpResponse(json.dumps({"error": str(e)}), status_code=500)
