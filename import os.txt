import gradio as gr
import mysql.connector
import json
from langchain_openai import AzureChatOpenAI
from langchain_core.tracers.stdout import ConsoleCallbackHandler
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.prebuilt import create_react_agent
from langchain_community.callbacks import get_openai_callback


# -------------------------------
# Configure Azure OpenAI
# -------------------------------
llm = AzureChatOpenAI(
    deployment_name="gpt-4_complex_conversions",
    azure_endpoint="https://testopenaiassets.openai.azure.com",
    openai_api_key="",
    openai_api_version="2025-01-01-preview"
)

# -------------------------------
# Configure MySQL (for logs)
# -------------------------------
config = {
    "host": "34.224.108.183",
    "user": "OSIF",
    "password": "123456@Cap",
    "database": "OSIF"
}

def fetch_logs():
    """Fetch logs or API performance data from MySQL."""
    conn = mysql.connector.connect(**config)
    cursor = conn.cursor(dictionary=True)
    try:
        cursor.execute("SELECT * FROM log_entries ORDER BY id DESC LIMIT 100")
        results = cursor.fetchall()
    except Exception as e:
        results = [{"error": str(e)}]
    cursor.close()
    conn.close()
    return results


# -------------------------------
# Create ReAct Agent (for coding/file analysis)
# -------------------------------
agent = create_react_agent(
    model=llm,
    tools=[],
    verbose=True
)


# -------------------------------
# Common Token Usage Wrapper
# -------------------------------
def run_with_token_tracking(func, *args, **kwargs):
    """Run an LLM function with token tracking and return response + usage info."""
    with get_openai_callback() as cb:
        result = func(*args, **kwargs)

        # Token usage details
        usage = "\n\n--- Token Usage ---"
        usage += f"\nTotal Tokens: {cb.total_tokens}"
        usage += f"\nPrompt Tokens: {cb.prompt_tokens}"
        usage += f"\nCompletion Tokens: {cb.completion_tokens}"
        usage += f"\nTotal Cost (USD): ${format(cb.total_cost, '.6f')}"

    return result, usage


# -------------------------------
# Chat Function - Combined
# -------------------------------
def chat_with_agent(user_prompt, history, file=None):
    """
    Decide whether to handle logs (Code 1) or coding/file (Code 2) 
    based on user question or file upload.
    """
    try:
        # If user uploaded a file or asks coding-related things → use Code 2 path
        if file is not None or any(keyword in user_prompt.lower() for keyword in ["code", "function", "error in", "fix", "class", "python", "java", "file"]):
            messages = []

            if history is not None:
                for user_msg, bot_msg in history:
                    messages.append(HumanMessage(content=user_msg))
                    messages.append(AIMessage(content=bot_msg))

            file_content = ""
            if file is not None:
                try:
                    with open(file.name, "r", encoding="utf-8", errors="ignore") as f:
                        file_content = f.read()
                except Exception as e:
                    file_content = f"[Error reading file: {e}]"

            if file_content:
                user_message = (
                    f"User question:\n{user_prompt}\n\n"
                    f"Attached file content:\n{file_content}\n"
                )
            else:
                user_message = user_prompt

            messages.append(HumanMessage(content=user_message))

            def invoke_agent():
                return agent.invoke(
                    {"messages": messages},
                    config={"callbacks": [ConsoleCallbackHandler()]}
                )

            result, usage = run_with_token_tracking(invoke_agent)
            final_response = result["messages"][-1].content + usage
            return final_response

        # Otherwise, assume logs-related → use Code 1 path
        else:
            results = fetch_logs()

            if not results or "error" in results[0]:
                return f"Could not fetch logs from DB: {results}"

            level_counts = {}
            for log in results:
                level = log.get("level", "UNKNOWN").upper()
                level_counts[level] = level_counts.get(level, 0) + 1

            summary = "\n".join([f"{level}: {count}" for level, count in level_counts.items()])
            debug_count = level_counts.get("DEBUG", 0)

            logs_str = json.dumps(results, indent=2, default=str)

            messages = [
                {
                    "role": "system",
                    "content": (
                        """
You are a highly experienced data analyst specializing in system and API log analysis.
Your task is to analyze structured log data provided to you...
(Instructions unchanged from Code 1)
"""
                    ),
                },
                {
                    "role": "user",
                    "content": (
                        f"{user_prompt}\n\n"
                        f"--- Log Summary ---\n{summary}\n\n"
                        f"Total DEBUG logs: {debug_count}\n\n"
                        f"--- Raw Logs (latest 100 rows) ---\n{logs_str}"
                    ),
                },
            ]

            def invoke_llm():
                return llm.invoke(messages, config={"callbacks": [ConsoleCallbackHandler()]})

            result, usage = run_with_token_tracking(invoke_llm)
            final_response = result.content + usage
            return final_response

    except Exception as e:
        return f"Error: {str(e)}"


# -------------------------------
# Gradio UI (Single)
# -------------------------------
chatbot_ui = gr.ChatInterface(
    fn=chat_with_agent,
    additional_inputs=[
        gr.File(
            label="Upload a file (optional)",
            file_types=[".txt", ".java", ".py", ".js", ".cpp", ".md", ".log", "*"]
        )
    ],
    title="OSIF Co-Developer",
    description="Ask about logs, coding, or upload a file. The AI will analyze and respond accordingly.",
    theme="default"
)


# -------------------------------
# Launch App
# -------------------------------
if __name__ == "__main__":
    chatbot_ui.launch(debug=False)