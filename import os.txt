import os
import logging
import json
import random
import string
from base64 import b64decode
from Crypto.Cipher import AES
from langchain_community.chat_models import AzureChatOpenAI
from langchain.schema import HumanMessage

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def unpad(data):
    padding_length = data[-1]
    return data[:-padding_length]

def decrypt(data, key):
    cipher = AES.new(b64decode(key), AES.MODE_ECB)
    decrypted_data = cipher.decrypt(b64decode(data))
    return unpad(decrypted_data).decode()

def get_openai_client(agent_name, model_instance_name):
    try:
        aes_key_base64 = os.environ['AES_KEY']
        encrypted_api_base = os.environ['ENCRYPTED_API_BASE']
        encrypted_api_key = os.environ['ENCRYPTED_API_KEY']
        api_version = os.environ['AZURE_API_VERSION']

        decrypted_api_base = decrypt(encrypted_api_base, aes_key_base64)
        decrypted_api_key = decrypt(encrypted_api_key, aes_key_base64)

        if not decrypted_api_base.endswith('/'):
            decrypted_api_base += '/'

        logger.info(f"Request URL: {decrypted_api_base}openai/deployments/{model_instance_name}/chat/completions?api-version={api_version}")

        return AzureChatOpenAI(
            deployment_name=model_instance_name,
            openai_api_base=decrypted_api_base,
            openai_api_key=decrypted_api_key,
            openai_api_version=api_version
        )
    except Exception as e:
        logger.error(f"OpenAI client initialization failed: {e}")
        raise ValueError(f"OpenAI client initialization failed: {e}")

def detect_agent_name(file_content):
    file_content = file_content.strip()

    if file_content.startswith("%dw"):
        return "dwl_json"
    elif file_content.startswith("#%RAML"):
        return "raml_json"
    elif file_content.startswith("<?xml"):
        if "xsl:stylesheet" in file_content or "<xsl:stylesheet" in file_content:
            return "xslt_json"
        else:
            return "xsd_json"
    elif file_content.startswith("swagger:") or "openapi:" in file_content:
        return "swagger_json"
    else:
        raise ValueError("Unsupported or unrecognized file type.")

def get_prompt(agent_name, iteration=None, total=None):
    base_instruction = ""

    if agent_name == "dwl_json":
        base_instruction = (
            "You are an expert in analyzing and converting DataWeave scripts into JSON structures. "
            "Analyze the attached dwl logic and generate a realistic sample input payload. "
            "Ensure the output is a different JSON data set for each request. "
        )
    elif agent_name == "raml_json":
        base_instruction = (
            "You are an expert in RAML and generating realistic example JSON payloads. "
            "Analyze the RAML content and create a realistic sample input JSON. "
            "Ensure each output is different when multiple sets are requested. "
        )
    elif agent_name == "xsd_json":
        base_instruction = (
            "You are an expert in XSD and can generate realistic JSON structures. "
            "Analyze the XML schema and produce one valid example JSON input. "
            "Ensure the generated JSON is different for each sample in repeated requests. "
        )
    elif agent_name == "swagger_json":
        base_instruction = (
            "You are an expert in Swagger/OpenAPI and can generate realistic JSON request bodies. "
            "Based on the Swagger spec, generate one valid and varied JSON object. "
            "Ensure output varies with each request when count > 1. "
        )
    elif agent_name == "xslt_json":
        base_instruction = (
            "You are an expert in XSLT and JSON test generation. "
            "Analyze the transformation rules and generate a realistic input JSON "
            "that would match expected transformation patterns. "
            "If multiple examples are needed, each must be different. "
        )
    else:
        raise ValueError(f"Unsupported agent name: {agent_name}")

    # Append count-specific instructions
    if iteration is not None and total is not None:
        base_instruction += f"\nThis is sample {iteration + 1} of {total}. Make this dataset different from others."

    return base_instruction

def process_with_openai(client, file_content, agent_name, count):
    results = []

    for i in range(count):
        prompt = get_prompt(agent_name, i, count)
        full_prompt = prompt + "\n\n" + file_content
        try:
            response = client.invoke([HumanMessage(content=full_prompt)])
            results.append(json.loads(response.content))
        except Exception as e:
            logger.error(f"OpenAI call failed on iteration {i+1}: {e}")
            raise

    return results if count > 1 else results[0]

def process_file_content(file_content, model_instance_name, count):
    agent_name = detect_agent_name(file_content)
    client = get_openai_client(agent_name, model_instance_name)
    return process_with_openai(client, file_content, agent_name, count)

def lambda_handler(event, context):
    logger.info(f"Received event: {json.dumps(event)}")

    try:
        if 'body' not in event or not event['isBase64Encoded']:
            raise ValueError("Missing or invalid file content.")

        file_content = b64decode(event['body']).decode('utf-8')
        headers = event.get('headers', {})

        model_instance_name = headers.get('model_instance_name')
        if not model_instance_name:
            raise ValueError("Missing 'model_instance_name' in headers.")

        count = int(headers.get('count', 1))  # default to 1 if not passed

        result = process_file_content(file_content, model_instance_name, count)

        return {
            "statusCode": 200,
            "headers": {"Content-Type": "application/json"},
            "body": json.dumps(result, indent=2)
        }

    except Exception as e:
        logger.error(f"Processing failed: {e}")
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }
