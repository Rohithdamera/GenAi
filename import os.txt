import os
from pathlib import Path

from langchain.chat_models import AzureChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.agents import initialize_agent, Tool
from langchain.memory import ConversationBufferMemory
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnableMap

# Azure OpenAI Configuration
def get_openai_client():
    return AzureChatOpenAI(
        azure_endpoint="https://testopenaiassets.openai.azure.com",
        deployment_name="Fourth_Chatbot",
        openai_api_key="",  # Set your Azure API key here
        openai_api_version="2024-08-01-preview",
        openai_api_type="azure",
        temperature=0.7,
        max_tokens=2000,
        top_p=0.9,
        frequency_penalty=0.2,
        presence_penalty=0.1
    )

# Globals
project_path = r"C:\\Users\\rdamera\\Downloads\\OrderManagement 1\\OrderManagement"
last_file_list = []
combined_summaries = ""

# === TOOL 1: Find only .xml files inside valid src/main/mule folders

def find_all_mule_xml_files(project_dir):
    xml_files = []
    for root, dirs, files in os.walk(project_dir):
        if any(part.lower() == "target" for part in Path(root).parts):
            continue

        normalized_root = os.path.normpath(root)
        if normalized_root.endswith(os.path.normpath(os.path.join("src", "main", "mule"))):
            for sub_root, _, sub_files in os.walk(root):
                for file in sub_files:
                    if file.lower().endswith(".xml"):
                        xml_files.append(os.path.normpath(os.path.join(sub_root, file)))
    return xml_files

def list_mule_xml_files(_: str) -> str:
    global last_file_list
    mule_xml_files = find_all_mule_xml_files(project_path)
    if not mule_xml_files:
        return "No XML files found under valid src/main/mule folders."

    last_file_list = mule_xml_files
    return f"Found {len(mule_xml_files)} MuleSoft XML files:\n" + "\n".join(mule_xml_files)

# === TOOL 2: Summarize all XML files without manual for-loop or threading

def summarize_all_files(_: str) -> str:
    if not last_file_list:
        return "No XML files loaded to summarize."

    client = get_openai_client()

    prompt = PromptTemplate(
        input_variables=["xml_content"],
        template="""
You are a MuleSoft expert. Analyze the following XML configuration and generate a concise technical summary:
- Identify any flows, subflows, or global elements
- Summarize the integration logic clearly

{xml_content}
"""
    )

    # Define the chain
    summarize_chain = (
        RunnablePassthrough()
        | RunnableLambda(lambda paths: [Path(path).read_text(encoding="utf-8") for path in paths])
        | RunnableLambda(lambda contents: [{"xml_content": c} for c in contents])
        | RunnableMap({"xml_content": RunnablePassthrough()})
        | prompt
        | client
        | StrOutputParser()
    )

    global combined_summaries
    combined_summaries = summarize_chain.invoke(last_file_list)

    return "All XML files have been summarized using LangChain's internal parallel processing."

# === TOOL 3: Generate final summary from all collected summaries

def generate_final_summary(_: str) -> str:
    if not combined_summaries:
        return "No summaries available to compile."

    client = get_openai_client()
    prompt_template = PromptTemplate(
        input_variables=["combined_summaries"],
        template="""
You are an expert in MuleSoft architecture. Summarize the following XML summaries into a single cohesive technical overview.
Include:
- Major flows/subflows
- Key global configurations or services
- Overall integration flow and purpose

{combined_summaries}
"""
    )
    chain = LLMChain(llm=client, prompt=prompt_template)
    return chain.run(combined_summaries="\n\n".join(combined_summaries) if isinstance(combined_summaries, list) else combined_summaries)

# === MAIN ===
if __name__ == "__main__":
    print("Initializing MuleSummarizerAgent with Tools and Memory...\n")

    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

    tools = [
        Tool(name="ListMuleXMLFiles", func=list_mule_xml_files, description="List XML files only under valid src/main/mule folders (excluding target folders)."),
        Tool(name="SummarizeAllFiles", func=summarize_all_files, description="Summarize all loaded Mule XML files."),
        Tool(name="GenerateFinalSummary", func=generate_final_summary, description="Generate final overview summary from all MuleSoft file summaries.")
    ]

    client = get_openai_client()
    agent = initialize_agent(
        tools=tools,
        llm=client,
        agent_type="openai-functions",
        memory=memory,
        verbose=True
    )

    print("MuleSummarizerAgent is now deciding what to do...\n")

    agent.invoke(
        "List all XML files only under src/main/mule folders in the project (not from target or build folders), summarize each one, and give a final project-level technical summary."
    )
