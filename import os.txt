import json
import requests
from langchain.chat_models import AzureChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough, RunnableLambda
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import LLMChain
from langchain.agents import Tool, initialize_agent
from langchain.memory import ConversationBufferMemory

# === MCP Server Configuration ===
MCP_URL = "https://your.mcp.server.url"  # ðŸ” Replace with actual URL
MCP_PAYLOAD = {
    "method": "tools/call",
    "params": {
        "name": "get-vendors",
        "arguments": {}
    }
}

# === Global store ===
mcp_raw_data = ""

# === Azure OpenAI Setup ===
def get_openai_client():
    return AzureChatOpenAI(
        azure_endpoint="https://testopenaiassets.openai.azure.com",
        deployment_name="Fourth_Chatbot",
        openai_api_key="",  # ðŸ”‘ Replace with your Azure key
        openai_api_version="2024-08-01-preview",
        openai_api_type="azure",
        temperature=0.5,
        max_tokens=1500,
        model_kwargs={"top_p": 0.9}
    )

# === TOOL 1: Step 1 â€” MCP Server Connection Check ===
def check_mcp_server(_: str) -> str:
    try:
        print("â³ Connecting to MCP server (up to 2.5 minutes)...")
        response = requests.get(MCP_URL, timeout=180)  # â²ï¸ Increased timeout to 3 minutes
        if response.status_code == 200:
            return "[SUCCESS] MCP server is reachable."
        return f"[FAILURE] MCP responded with status code: {response.status_code}"
    except Exception as e:
        return f"[ERROR] MCP connection failed: {str(e)}"

# === TOOL 2: Step 2 â€” Fetch data from MCP server ===
def fetch_mcp_data(_: str) -> str:
    global mcp_raw_data
    try:
        print("â³ Sending POST request to MCP server (up to 3 minutes)...")
        response = requests.post(MCP_URL, json=MCP_PAYLOAD, timeout=180)  # â²ï¸ 3 minutes timeout
        response.raise_for_status()
        mcp_raw_data = json.dumps(response.json(), indent=2)
        return "[SUCCESS] MCP data fetched and stored."
    except Exception as e:
        return f"[ERROR] MCP data fetch failed: {str(e)}"

# === TOOL 3: Step 3 â€” Summarize the response ===
def summarize_mcp_data(_: str) -> str:
    global mcp_raw_data
    if not mcp_raw_data:
        return "[SKIP] No MCP data found. Please run fetch step first."

    try:
        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        chunks = splitter.split_text(mcp_raw_data)

        client = get_openai_client()
        prompt = PromptTemplate(
            input_variables=["chunk"],
            template="""
You are an assistant. Summarize the following JSON chunk about vendor data in simple, clear language.

Highlight:
- Key vendor names or info
- Configurations or fields present
- Important values or relationships

Chunk:
{chunk}
"""
        )
        summarize_chain = LLMChain(llm=client, prompt=prompt)
        all_summaries = [summarize_chain.run({"chunk": c}) for c in chunks]
        return "\n\n".join(all_summaries)

    except Exception as e:
        return f"[ERROR] Failed to summarize MCP data: {str(e)}"

# === LangChain Agent Setup ===
def run_agent():
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

    tools = [
        Tool(
            name="CheckMCPServer",
            func=check_mcp_server,
            description="Step 1: Check if MCP server is reachable (may take ~2 mins)."
        ),
        Tool(
            name="FetchMCPData",
            func=fetch_mcp_data,
            description="Step 2: Fetch vendor data from MCP server (may take ~1 min)."
        ),
        Tool(
            name="SummarizeMCPData",
            func=summarize_mcp_data,
            description="Step 3: Summarize the vendor data into user-friendly format."
        )
    ]

    agent = initialize_agent(
        tools=tools,
        llm=get_openai_client(),
        agent_type="openai-functions",
        memory=memory,
        verbose=True
    )
    return agent

# === MAIN EXECUTION ===
if __name__ == "__main__":
    print("ðŸ”§ Initializing MCP Workflow Agent...")
    agent = run_agent()

    print("\nðŸš€ Running Step-by-Step MCP Data Extraction...\n")
    result = agent.invoke("First check the MCP server, then fetch vendor data and finally summarize it.")
    print("\nâœ… Final Output:\n")
    print(result)
