import os
import json
import logging
from base64 import b64decode
from Crypto.Cipher import AES
from langchain_community.chat_models import AzureChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

logging.basicConfig(level=logging.INFO)

def unpad(data: bytes) -> bytes:
    return data[:-data[-1]]

def decrypt(data: str, key: str) -> str:
    cipher = AES.new(b64decode(key), AES.MODE_ECB)
    return unpad(cipher.decrypt(b64decode(data))).decode()

def get_openai_client(model_instance_name: str) -> AzureChatOpenAI:
    aes_key = os.environ['AES_KEY']
    api_base = decrypt(os.environ['ENCRYPTED_API_BASE'], aes_key)
    api_key = decrypt(os.environ['ENCRYPTED_API_KEY'], aes_key)
    api_version = os.environ['AZURE_API_VERSION']

    if not api_base.endswith('/'):
        api_base += '/'

    return AzureChatOpenAI(
        deployment_name=model_instance_name,
        openai_api_base=api_base,
        openai_api_key=api_key,
        openai_api_version=api_version,
        temperature=0.7,
        max_tokens=4096,
        model_kwargs={
            "top_p": 0.9,
            "frequency_penalty": 0.2,
            "presence_penalty": 0.3
        }
    )

REFINED_DEFAULT_PROMPT = (
    "You are a senior BizTalk Integration Architect specialized in Orchestration (.odx files) and Azure DevOps Documentation.\n\n"
    "Instructions:\n"
    "1. At the top of the Markdown output, include a red-colored disclaimer: '**⚠️ This Markdown file is autogenerated by AI. Please verify before use.**'\n"
    "2. Generate a clear and valid **Mermaid diagram** enclosed between :::mermaid and ::: markers.\n"
    "3. After the diagram, add a section called `### Orchestration Flow Steps`.\n"
    "   - List the flow in **step-by-step numbered bullets**.\n"
    "   - Each step should explain the component or action in detail (e.g., 'Receive Shape receives the XML order', 'Construct Message uses Transform_1 to map input to schema').\n"
    "4. Add a section titled `### Description`:\n"
    "   - Summarize the overall process.\n"
    "   - Mention schemas, maps, ports, exception handling, and any important patterns used.\n"
    "5. If the file contains configuration JSON instead of ODX, describe the structure and purpose of the configuration in similar markdown format.\n\n"
    "Use proper Azure DevOps markdown syntax: https://learn.microsoft.com/en-us/azure/devops/project/wiki/markdown-guidance\n"
    "Use valid Mermaid syntax from: https://mermaid.js.org/\n"
)

def process_with_openai(client: AzureChatOpenAI, file_text: str, prompt: str) -> str:
    system_msg = SystemMessage(content=prompt)
    user_msg = HumanMessage(content=file_text)
    response = client.invoke([system_msg, user_msg]).content.strip()
    return response.replace("\\n", "\n")

def detect_file_type_and_decode(raw_body: str) -> str:
    try:
        return raw_body.decode('utf-8')
    except Exception:
        raise ValueError("Uploaded file must be a valid UTF-8 encoded .odx or .json file")

def lambda_handler(event: dict, context: dict) -> dict:
    try:
        raw_body = event.get('body')
        if not raw_body:
            raise ValueError("Missing request body.")

        # Decode binary if required
        if event.get("isBase64Encoded", False):
            raw_body = b64decode(raw_body)
        else:
            raw_body = raw_body.encode('utf-8')

        headers = event.get('headers', {})
        model_instance_name = headers.get('model_instance_name')
        if not model_instance_name:
            raise ValueError("Missing 'model_instance_name' in headers.")

        # Dynamic prompt override
        custom_prompt = headers.get('prompt', '').strip()
        final_prompt = custom_prompt if custom_prompt else REFINED_DEFAULT_PROMPT

        file_text = detect_file_type_and_decode(raw_body)
        client = get_openai_client(model_instance_name)
        result = process_with_openai(client, file_text, final_prompt)

        return {
            "statusCode": 200,
            "headers": {"Content-Type": "application/json"},
            "body": json.dumps({"output": result})
        }

    except Exception as e:
        logging.error(f"Error: {e}")
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }
