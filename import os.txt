import os
from pathlib import Path

from langchain.chat_models import AzureChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# Azure OpenAI Configuration
def get_openai_client():
    return AzureChatOpenAI(
        azure_endpoint="https://testopenaiassets.openai.azure.com",
        deployment_name="Fourth_Chatbot",
        openai_api_key="",  # Replace with your key
        openai_api_version="2024-08-01-preview",
        openai_api_type="azure",
        temperature=0.7,
        max_tokens=2000,
        top_p=0.9,
        frequency_penalty=0.2,
        presence_penalty=0.1
    )

# Get all .xml files under src/main/mule
def get_all_xml_files(project_dir):
    mule_dir = Path(project_dir) / "src" / "main" / "mule"
    return [str(f) for f in mule_dir.rglob("*.xml")]

# Read raw content as string
def read_xml_file(file_path: str) -> str:
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception as e:
        return f"Error reading {file_path}: {str(e)}"

# Summarize a single XML string
def summarize_xml(xml_content: str, client) -> str:
    prompt_template = PromptTemplate(
        input_variables=["xml_content"],
        template="""You are an expert in MuleSoft XML configuration.
Analyze the following XML and generate a clear, concise summary of its integration logic.
Focus only on meaningful Mule components like flows, subflows, and configuration patterns.

{xml_content}
"""
    )
    chain = LLMChain(llm=client, prompt=prompt_template)
    return chain.run(xml_content=xml_content)

# Combine all file-level summaries into a final summary
def generate_final_summary(summaries: list[str], client) -> str:
    combined = "\n\n".join(summaries)
    prompt_template = PromptTemplate(
        input_variables=["combined_summaries"],
        template="""You are an expert in summarizing complex XML-based MuleSoft projects.
Provide a single, high-level technical summary that captures the main integration patterns and logic across all files.

{combined_summaries}
"""
    )
    chain = LLMChain(llm=client, prompt=prompt_template)
    return chain.run(combined_summaries=combined)

# MAIN
if __name__ == "__main__":
    project_path = r"C:\\Users\\rdamera\\Downloads\\OrderManagement 1"
    client = get_openai_client()

    print("🔍 Scanning for XML files...")
    xml_files = get_all_xml_files(project_path)

    print(f"📂 Found {len(xml_files)} XML files. Processing summaries...")
    summaries = []

    for file_path in xml_files:
        xml_content = read_xml_file(file_path)
        summary = summarize_xml(xml_content, client)
        summaries.append(summary)

    print("\n🧠 Generating final summary...")
    final_summary = generate_final_summary(summaries, client)

    print("\n✅ Final MuleSoft Project Summary:\n")
    print(final_summary)
