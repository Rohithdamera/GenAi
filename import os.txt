import mysql.connector
from datetime import datetime
import matplotlib.pyplot as plt
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
import openai
import os

# Set OpenAI Azure configurations
os.environ["OPENAI_API_TYPE"] = "azure"
os.environ["OPENAI_API_KEY"] = ""  # Add your key here
os.environ["OPENAI_API_BASE"] = "https://testopenaiassets.openai.azure.com/"
os.environ["OPENAI_API_VERSION"] = "2024-08-01-preview"

# User input
api_name = input("Enter the API name (e.g., EXA-api): ").strip()
time_interval = input("Enter the time interval (e.g., 3 HOUR, 1 DAY): ").strip().upper()

# Connect to MySQL
conn = mysql.connector.connect(
    host="localhost",
    user="root",
    password="Admin",
    database="test_data"
)
cursor = conn.cursor()

# SQL query
sql_query = f"""
SELECT *
FROM `all api last 1 week performance report`
WHERE `API Name` = %s
  AND Timestamp BETWEEN (NOW() - INTERVAL {time_interval}) AND NOW()
ORDER BY `API Name`, Timestamp ASC;
"""

cursor.execute(sql_query, (api_name,))
results = cursor.fetchall()
column_names = [desc[0] for desc in cursor.description]
conn.close()

# Prepare results as string
results_str = "\n".join(
    [", ".join(f"{col}: {val}" for col, val in zip(column_names, row)) for row in results]
)

# Summarization prompt
system_prompt = f"""
You are a helpful data analyst.
The user will provide performance metrics for the API '{api_name}' over the past {time_interval}.
The data includes response time, error rate, request volume, timestamp, and status codes.

Your task is to:
- Briefly describe the overall health.
- Mention if there are any major issues.
- Explain any noticeable patterns (like increased error rate or slow response).
- Suggest 1-2 possible improvements.

Be concise and easy to understand for non-technical users.
"""

# LangChain summarization
llm = ChatOpenAI(deployment_name="Fourth_Chatbot", temperature=0.5, max_tokens=700)

messages = [
    SystemMessage(content=system_prompt),
    HumanMessage(content=results_str)
]

try:
    summary = llm(messages).content
    print("\n\n--- API Performance Summary ---\n")
    print(summary)
except Exception as e:
    print(f"LangChain summary error: {e}")

# ---------------------------
# Pie chart generation logic
# ---------------------------
try:
    status_col_index = column_names.index("Status Code")
    status_counts = {"200+": 0, "400+": 0, "Other": 0}

    for row in results:
        status = int(row[status_col_index])
        if 200 <= status < 300:
            status_counts["200+"] += 1
        elif 400 <= status < 500:
            status_counts["400+"] += 1
        else:
            status_counts["Other"] += 1

    # Pie chart
    labels = status_counts.keys()
    sizes = status_counts.values()
    colors = ['#4CAF50', '#F44336', '#FFC107']

    plt.figure(figsize=(5, 5))
    plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=140)
    plt.title(f"API Status Distribution: {api_name}")
    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
    plt.tight_layout()
    plt.savefig("api_status_pie_chart.png")
    plt.show()
    print("\nPie chart generated and displayed.")
except Exception as e:
    print(f"Error creating pie chart: {e}")
