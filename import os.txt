import os
import json
import asyncio
import logging
from typing import List, Dict, Any

from langchain.agents import PlanAndExecute, load_agent_executor, load_chat_planner
from langchain.tools import Tool
from langchain_core.tools import tool
from langchain_community.chat_models import AzureChatOpenAI
from aiohttp import ClientSession
from contextlib import asynccontextmanager

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === Azure OpenAI Client ===
def get_openai_client():
    return AzureChatOpenAI(
        azure_deployment="Fourth_Chatbot",
        azure_endpoint="https://testopenaiassets.openai.azure.com",
        openai_api_version="2024-08-01-preview",
        openai_api_key=os.getenv("AZURE_OPENAI_KEY", ""),  # Store your key securely
        temperature=0.7,
        max_tokens=2000,
        model_kwargs={
            "top_p": 0.9,
            "frequency_penalty": 0.2,
            "presence_penalty": 0.1
        }
    )

# === SSE MCP TOOL DISCOVERY CLIENT ===
sse_url = "https://employee-mcp-v1-6b0n6.dw4w1g-2.gbr-e1.cloudhub.io/sse"

@asynccontextmanager
async def sse_client(url):
    async with ClientSession() as session:
        yield session

# === SYNC WRAPPER FOR TOOL FETCHING ===
def sync_fetch_tools() -> List[Dict[str, Any]]:
    async def fetch():
        async with sse_client(url=sse_url) as session:
            async with session.get(f"{sse_url}/tools") as response:
                if response.status != 200:
                    raise Exception(f"SSE fetch failed with status {response.status}")
                return await response.json()
    return asyncio.get_event_loop().run_until_complete(fetch())

# === DYNAMIC TOOL CREATION FROM MCP ===
def generate_tools_from_mcp() -> List[Tool]:
    raw_tools = sync_fetch_tools()
    tools = []

    for tool_data in raw_tools.get("tools", []):
        name = tool_data.get("name")
        description = tool_data.get("description", "")
        input_schema = tool_data.get("inputSchema", {})

        @tool(name=name, description=description)
        def dynamic_tool(**kwargs):
            try:
                payload = json.dumps(kwargs)
                response = asyncio.get_event_loop().run_until_complete(call_mcp_api(name, payload))
                return response
            except Exception as e:
                return f"[ERROR] Failed to call tool {name}: {e}"

        tools.append(dynamic_tool)

    return tools

# === API CALLER FOR TOOLS ===
async def call_mcp_api(tool_name: str, payload: str):
    url = f"{sse_url}/tools/{tool_name}/run"
    headers = {
        "Content-Type": "application/json"
    }
    async with ClientSession() as session:
        async with session.post(url, data=payload, headers=headers) as resp:
            if resp.status == 200:
                return await resp.text()
            else:
                return f"[ERROR] MCP call failed for {tool_name}, status: {resp.status}"

# === BUILD PLAN-AND-EXECUTE AGENT ===
def build_plan_and_execute_agent():
    llm = get_openai_client()
    tools = generate_tools_from_mcp()
    planner = load_chat_planner(llm)
    executor = load_agent_executor(llm=llm, tools=tools, verbose=True)
    agent = PlanAndExecute(planner=planner, executor=executor, verbose=True)
    return agent

# === MAIN ENTRY POINT ===
def run_agent_on_query(user_query: str) -> str:
    try:
        agent = build_plan_and_execute_agent()
        result = agent.invoke({"input": user_query})
        return result.get("output", "No result returned.")
    except Exception as e:
        return f"[ERROR] Agent execution failed: {e}"

# === TEST ===
if __name__ == "__main__":
    test_query = "Give me the names of employees working in the Pepsico project with less than 10 years of experience"
    output = run_agent_on_query(test_query)
    print("\n=== AGENT RESPONSE ===\n")
    print(output)
