import gradio as gr
from langgraph.prebuilt import create_react_agent
from langchain_openai import AzureChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langchain.callbacks.tracers import ConsoleCallbackHandler
from langchain_community.callbacks import get_openai_callback

# Create a local reference to remote LLM model
llm = AzureChatOpenAI(
    deployment_name="gpt-4_complex_conversions",
    azure_endpoint="https://testopenaiassets.openai.azure.com",
    openai_api_key="",  # put your API key
    openai_api_version="2025-01-01-preview",
)

# Agent
agent = create_react_agent(
    model=llm,
    tools=[],
    verbose=True
)

# Chatbot function
def chat_with_agent(message, history, file=None):
    messages = []

    # Ensure history exists
    if history is not None:
        for user_msg, bot_msg in history:
            messages.append(HumanMessage(content=user_msg))
            messages.append(AIMessage(content=bot_msg))

    # If a file is uploaded, read its contents
    file_content = ""
    if file is not None:
        try:
            with open(file.name, "r", encoding="utf-8", errors="ignore") as f:
                file_content = f.read()
        except Exception as e:
            file_content = f"[Error reading file: {e}]"

    # Construct user message (question + file if present)
    if file_content:
        user_message = (
            f"User question:\n{message}\n\n"
            f"Attached file content:\n{file_content}\n"
        )
    else:
        user_message = message

    messages.append(HumanMessage(content=user_message))

    # Call agent
    try:
        with get_openai_callback() as cb:
            result = agent.invoke(
                {"messages": messages},
                config={"callbacks": [ConsoleCallbackHandler()]}
            )
            final_response = result["messages"][-1].content

            # Add usage info
            final_response += "\n\n--- Token Usage ---"
            final_response += f"\nTotal Tokens: {cb.total_tokens}"
            final_response += f"\nPrompt Tokens: {cb.prompt_tokens}"
            final_response += f"\nCompletion Tokens: {cb.completion_tokens}"
            final_response += f"\nTotal Cost (USD): ${format(cb.total_cost, '.6f')}"
    finally:
        print("Interaction completed")

    return final_response

# Gradio Chat Interface
chatbot_ui = gr.ChatInterface(
    fn=chat_with_agent,
    additional_inputs=[
        gr.File(
            label="Upload a file (optional)",
            file_types=[".txt", ".java", ".py", ".js", ".cpp", ".md", ".log", "*"]
        )
    ],
    title="OSIF Co-Developer",
    description="Ask coding or log-related questions, paste code, or upload files. The AI will analyze and answer based on your prompt and the file content.",
    theme="default"
)

# Launch app
chatbot_ui.launch(debug=False)