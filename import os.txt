merge the code1 and code 2 into one , dont change anything in the code 1 like code functionality, prompts , tools , code structure keep everything same , just merge the code 2 with code1 , what ever the data that will generate related token like(Total Tokens, prompt tokens etc) keep the token thing in one method or class , when ever token  required  only it need to be called , instead of declaring it multiple places , keep only one box in ui , that handle any kind of . files , dont change anything in the ui , give ,me full updated code 


code1:

import os
import yaml
import json
import re
from pathlib import Path
from typing import List, Dict
import gradio as gr
import boto3
from langchain.prompts import PromptTemplate
from langchain_openai import AzureChatOpenAI
from langchain.tools import Tool
from langchain.callbacks import get_openai_callback

# ====================================================
# Azure OpenAI Client
# ====================================================
def get_openai_client():
    return AzureChatOpenAI(
        azure_endpoint="https://testopenaiassets.openai.azure.com",
        deployment_name="gpt-4_complex_conversions",
        openai_api_key="",
        openai_api_version="2025-01-01-preview",
        openai_api_type="azure",
        temperature=0.3,
        max_tokens=2000,
    )

llm = get_openai_client()

# ====================================================
# Utility: Token Tracking Wrapper
# ====================================================
def run_with_token_tracking(func, *args, **kwargs):
    aggregated_token_usage = {
        "total_tokens": 0,
        "prompt_tokens": 0,
        "completion_tokens": 0,
        "total_cost": 0.0,
    }

    with get_openai_callback() as cb:
        result = func(*args, **kwargs)
        aggregated_token_usage["total_tokens"] += cb.total_tokens
        aggregated_token_usage["prompt_tokens"] += cb.prompt_tokens
        aggregated_token_usage["completion_tokens"] += cb.completion_tokens
        aggregated_token_usage["total_cost"] += cb.total_cost

    usage_summary = "\n\n--- Token Usage ---"
    usage_summary += f"\nTotal Tokens: {aggregated_token_usage['total_tokens']}"
    usage_summary += f"\nPrompt Tokens: {aggregated_token_usage['prompt_tokens']}"
    usage_summary += f"\nCompletion Tokens: {aggregated_token_usage['completion_tokens']}"
    usage_summary += f"\nTotal Cost (USD): ${format(aggregated_token_usage['total_cost'], '.6f')}"

    return result, usage_summary

# ====================================================
# Agent 1: YAML Model Class Generator
# ====================================================
def generate_model_from_yaml(prompt: str, yaml_file) -> str:
    try:
        with open(yaml_file.name, "r", encoding="utf-8") as f:
            yaml_text = f.read()
        yaml.safe_load(yaml_text)

        full_prompt = (
            "You are a senior Java developer. A developer will provide you with a YAML configuration file. "
            "Your task is to generate Java model classes only for the fields that are explicitly marked or structured with class paths. "
            "Each class path (e.g., `com.example.config.MyConfig`) should be used as the fully qualified name of the class. "
            "Use nested classes or separate classes as needed based on the YAML structure. "
            "Use lombok annotations to generate getters, setters and constructors. "
            "Do not include explanations or comments. Output only the Java class code. "
            "Whenever a class is end use this line ----------- and give a line break."
            "Give the conclusion like which classes are created classes. "
            f"\n\nPrompt: {prompt}\n\nHere is the YAML:\n\n{yaml_text}"
        )

        def _call_llm():
            return llm.invoke(full_prompt)

        response, usage = run_with_token_tracking(_call_llm)
        return response.content.strip() + usage

    except Exception as e:
        return f"[ERROR] Failed to process YAML: {str(e)}"

class ModelAgent:
    def run(self, prompt, yaml_file):
        return generate_model_from_yaml(prompt, yaml_file)

# ====================================================
# Agent 2: JUnit Generator
# ====================================================
def list_java_files(path: str) -> List[Path]:
    base_path = Path(path)
    if not base_path.exists():
        raise FileNotFoundError(f"Path not found: {path}")
    return list(base_path.rglob("*.java"))

def extract_code_info(java_paths: List[Path]) -> List[Dict]:
    prompt = PromptTemplate(
        input_variables=["source"],
        template="""
Return ONLY compact JSON describing this Java class with these keys:
class_name
class_type (must be exactly: "Controller", "Service", "Repository", "Config", "Entity", "DTO", "Main")
package_path
methods: list of all public method names
uses_repository: true/false
If class_type == "Entity", also include:
"entity_fields": list of {{"name": fieldName, "type": fieldType}}
Rules:
Do not explain.
Do not invent other class_type values.
Always valid JSON.
Java Source:
{source}
"""
    )
    chain = prompt | llm
    parsed = []

    for file_path in java_paths:
        try:
            source = file_path.read_text(encoding="utf-8")
            response = chain.invoke({"source": source})
            data = json.loads(response.content.strip())
            parsed.append(data)
        except Exception as e:
            print(f"[WARN] Failed to parse {file_path}: {e}")
    return parsed

def generate_junit_tests(parsed_info: List[Dict]) -> List[Dict]:
    ALLOWED_TYPES = {"Controller", "Service"}
    entity_map = {item["class_name"]: item.get("entity_fields", []) for item in parsed_info if item.get("class_type") == "Entity"}
    prompt = PromptTemplate(
        input_variables=[
            "class_name", "class_type", "package_path", "methods", "uses_repository", "entity_map"
        ],
        template="""
Write a complete JUnit 5 test class for:
Class Name: {class_name}
Type: {class_type}
Package: {package_path}
Public Methods:
{methods}
uses_repository: {uses_repository}
Available Entities:
{entity_map}
Rules:
1. Controllers
Use @WebMvcTest, MockMvc, @MockBean, ObjectMapper.
Test all endpoints, mock services, assert JSON with jsonPath.
Check all fields, not just IDs.
2. Services
Use Mockito if repository exists (@ExtendWith, @Mock, @InjectMocks).
Otherwise instantiate directly.
Populate full entities in @BeforeEach.
Assert with assertThat for all fields.
3. Entity population
Strings → "John Doe"
UUID → UUID.randomUUID().toString()
Lists → Arrays.asList("Java","Spring")
LocalDateTime → "2025-07-25T10:00:00"
int → 123
boolean → true
4. General
One @Test per public method.
Valid compilable Java code only.
"""
    )
    chain = prompt | llm
    test_classes = []

    for item in parsed_info:
        if item["class_type"] not in ALLOWED_TYPES:
            print(f"[SKIP] {item['class_name']} ({item['class_type']})")
            continue
        try:
            result = chain.invoke({
                "class_name": item["class_name"],
                "class_type": item["class_type"],
                "package_path": item["package_path"],
                "methods": "\n".join(item["methods"]),
                "uses_repository": str(item.get("uses_repository", False)).lower(),
                "entity_map": json.dumps(entity_map, indent=2),
            })
            test_classes.append({
                "file_name": f"{item['class_name']}Test.java",
                "package_path": item["package_path"],
                "code": result.content.strip(),
            })
        except Exception as e:
            print(f"[WARN] Could not generate test for {item['class_name']}: {e}")
    return test_classes

def save_and_print_tests(junit_tests: List[Dict]) -> str:
    output = ""
    for test in junit_tests:
        folder = Path("generated_tests") / test["package_path"].replace(".", "/")
        folder.mkdir(parents=True, exist_ok=True)
        file_path = folder / test["file_name"]
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(test["code"])
        output += f"\n===== {test['file_name']} =====\n{test['code']}\n===== End of {test['file_name']} =====\n"
    return output.strip()

tools = [
    Tool(name="ListJavaFiles", func=list_java_files, description="Lists all Java files."),
    Tool(name="ExtractCodeInfo", func=extract_code_info, description="Parses each Java file."),
    Tool(name="GenerateJUnitTests", func=generate_junit_tests, description="Generates JUnit 5 test classes."),
    Tool(name="SaveJUnitTests", func=save_and_print_tests, description="Saves tests to disk and prints them."),
]

def process_java_project(user_input: str) -> str:
    try:
        path_match = re.search(r"([A-Za-z]:[\\/\w\-. ]+)", user_input)
        if not path_match:
            return "[ERROR] Please provide a valid Windows file path."
        project_path = path_match.group(1).strip()

        def _process():
            java_files = tools[0].func(project_path)
            if not java_files:
                return "[INFO] No Java files found."
            parsed_info = tools[1].func(java_files)
            if not parsed_info:
                return "[INFO] No parsable Java classes found."
            junit_tests = tools[2].func(parsed_info)
            if not junit_tests:
                return "[INFO] No JUnit tests could be generated for allowed types."
            return tools[3].func(junit_tests)

        output_code, usage_summary = run_with_token_tracking(_process)
        return output_code + usage_summary
    except Exception as e:
        return f"[ERROR] {str(e)}"

class JUnitAgent:
    def run(self, user_input):
        return process_java_project(user_input)

# ====================================================
# Agent 3: Connector Detection (Replaced with dynamic S3 lookup)
# ====================================================
s3 = boto3.client(
    "s3",
    aws_access_key_id="AKIA6ODVATHCN52UKSRUO",
    aws_secret_access_key="N3+vw0XS4ZcdzqM0Zk6qflR7UbNy0ztQgdwWoiuEO",
    region_name="us-east-1"
)

S3_BUCKET = "osif-files"
S3_KEY = "OSIF_Dependency_req.txt"

def load_s3_file():
    obj = s3.get_object(Bucket=S3_BUCKET, Key=S3_KEY)
    return obj["Body"].read().decode("utf-8")

def extract_block(content, query):
    query = query.lower()
    match = re.search(r"(sales[- ]?force|sqs|crossaccountsqs|s3|common-api-library)", query, re.IGNORECASE)
    if not match:
        return "Could not identify connector from your question."

    connector_name = match.group(1).replace(" ", "").lower()
    blocks = re.split(r"(?=Title\s*:)", content, flags=re.IGNORECASE)

    for block in blocks:
        if not block.strip():
            continue
        if connector_name in block.lower().replace(" ", ""):
            return block.strip()

    return f"Connector '{connector_name}' not found in file."

class ConnectorAgent:
    def run(self, message: str) -> str:
        try:
            content = load_s3_file()
            return extract_block(content, message)
        except Exception as e:
            return f"[ERROR] {str(e)}"

# ====================================================
# Agent 4: Java Client Class Generator
# ====================================================
class ClientClassAgent:
    def run(self, prompt: str, java_file) -> str:
        try:
            with open(java_file.name, "r", encoding="utf-8") as f:
                java_code = f.read()
            full_prompt = (
                "You are a senior Java developer. A developer will provide you with a Java class. "
                "Analyze the java code and create client class for that. Use constructor injection and annotations also. "
                "Include the method which is there in the Java class it prints access token and instance URL, and handles exceptions. "
                "Do not include explanations or comments. Output only the Java class code. "
                f"\n\nPrompt: {prompt}\n\nHere is the Java class:\n\n{java_code}"
            )
            response = llm.invoke(full_prompt)
            return response.content.strip()
        except Exception as e:
            return f"[ERROR] Failed to process Java file: {str(e)}"

# ====================================================
# Unified Chatbot Function
# ====================================================
model_agent = ModelAgent()
junit_agent = JUnitAgent()
connector_agent = ConnectorAgent()
client_agent = ClientClassAgent()

def unified_chatbot(prompt, history, uploaded_files=None):
    """
    Note: uploaded_files may be:
      - None
      - a single file-like object
      - a list of file-like objects (when file_count='multiple' and user uploads multiple files)
    We map those to yaml_file / java_file to preserve existing code expectations.
    """
    lower_prompt = prompt.lower()

    # Normalize uploaded_files into yaml_file / java_file variables expected by downstream logic
    yaml_file = None
    java_file = None
    if uploaded_files is not None:
        # If a single file object is passed (not a list), convert to list for uniform handling
        uploaded_list = uploaded_files if isinstance(uploaded_files, list) else [uploaded_files]
        for f in uploaded_list:
            try:
                suffix = Path(f.name).suffix.lower()
            except Exception:
                # If there is no name attribute or unexpected object, skip
                continue
            if suffix in (".yml", ".yaml") and yaml_file is None:
                yaml_file = f
            elif suffix == ".java" and java_file is None:
                java_file = f
            # If both found, break early
            if yaml_file is not None and java_file is not None:
                break

    # Case 1: JUnit generation
    if "junit" in lower_prompt:
        return junit_agent.run(prompt)

    # Case 2: Model class generation
    if "model" in lower_prompt or "model class" in lower_prompt:
        if yaml_file is None:
            return "[ERROR] Please upload a YAML file for model class generation."
        return model_agent.run(prompt, yaml_file)

    # Case 3: Client class generation
    if "client class" in lower_prompt or java_file is not None:
        if java_file is None:
            return "[ERROR] Please upload a Java file for client class generation."
        return client_agent.run(prompt, java_file)

    # Case 4: Connector detection
    if any(k in lower_prompt for k in ["salesforce", "sfdc", "sqs", "s3", "common api"]):
        return connector_agent.run(prompt)

    # Fallbacks
    if yaml_file is not None:
        return model_agent.run(prompt, yaml_file)
    elif java_file is not None:
        return client_agent.run(prompt, java_file)
    elif re.search(r"([A-Za-z]:[\\/\w\-. ]+)", prompt):
        return junit_agent.run(prompt)
    else:
        return "[ERROR] Please upload a YAML file with prompt for models, a Java file for client class, or provide a valid file path for JUnit generation."

# ====================================================
# Gradio Chat Interface
# ====================================================
chatbot_ui = gr.ChatInterface(
    fn=unified_chatbot,
    title="OSIF_Co-Developer",
    description=(
        "Options:\n"
        "1. Upload a YAML file and enter a prompt like: `generate model class from this config`\n"
        "2. Provide a Windows file path like: `C:\\Users\\project\\src` to generate JUnit tests.\n"
        "3. Ask connector questions: e.g., `give connector properties of (salesforce, SQS, s3, CrossAccountSQS)`\n"
        "4. Upload a Java file and enter a prompt like: `create client class`"
    ),
    additional_inputs=[
        # Single upload box for both YAML and Java files. Allows multiple files but shows only one box in browser.
        gr.File(label="Upload File (YAML or Java)", file_types=[".yaml", ".yml", ".java"], file_count="multiple"),
    ],
    theme="default"
)

if __name__ == "__main__":
    print("Starting Unified Generator...")
    chatbot_ui.launch()



--------------------------------------------------------------------------------------------------------------------

code 2:


import gradio as gr
import mysql.connector
import json
from langchain_openai import AzureChatOpenAI
from langchain_core.tracers.stdout import ConsoleCallbackHandler
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.prebuilt import create_react_agent
from langchain_community.callbacks import get_openai_callback


# -------------------------------
# Configure Azure OpenAI
# -------------------------------
llm = AzureChatOpenAI(
    deployment_name="gpt-4_complex_conversions",
    azure_endpoint="https://testopenaiassets.openai.azure.com",
    openai_api_key="",
    openai_api_version="2025-01-01-preview"
)

# -------------------------------
# Configure MySQL (for logs)
# -------------------------------
config = {
    "host": "34.224.108.184",
    "user": "OSIF",
    "password": "12345@Cap",
    "database": "OSIF"
}

def fetch_logs():
    """Fetch logs or API performance data from MySQL."""
    conn = mysql.connector.connect(**config)
    cursor = conn.cursor(dictionary=True)
    try:
        cursor.execute("SELECT * FROM log_entries ORDER BY id DESC LIMIT 100")
        results = cursor.fetchall()
    except Exception as e:
        results = [{"error": str(e)}]
    cursor.close()
    conn.close()
    return results


# -------------------------------
# Create ReAct Agent (for coding/file analysis)
# -------------------------------
agent = create_react_agent(
    model=llm,
    tools=[],
    verbose=True
)


# -------------------------------
# Common Token Usage Wrapper
# -------------------------------
def run_with_token_tracking(func, *args, **kwargs):
    """Run an LLM function with token tracking and return response + usage info."""
    with get_openai_callback() as cb:
        result = func(*args, **kwargs)

        # Token usage details
        usage = "\n\n--- Token Usage ---"
        usage += f"\nTotal Tokens: {cb.total_tokens}"
        usage += f"\nPrompt Tokens: {cb.prompt_tokens}"
        usage += f"\nCompletion Tokens: {cb.completion_tokens}"
        usage += f"\nTotal Cost (USD): ${format(cb.total_cost, '.6f')}"

    return result, usage


# -------------------------------
# Chat Function - Combined
# -------------------------------
def chat_with_agent(user_prompt, history, file=None):
    """
    Decide whether to handle logs (Code 1) or coding/file (Code 2) 
    based on user question or file upload.
    """
    try:
        # If user uploaded a file or asks coding-related things → use Code 2 path
        if file is not None or any(keyword in user_prompt.lower() for keyword in ["code", "function", "error in", "fix", "class", "python", "java", "file"]):
            messages = []

            if history is not None:
                for user_msg, bot_msg in history:
                    messages.append(HumanMessage(content=user_msg))
                    messages.append(AIMessage(content=bot_msg))

            file_content = ""
            if file is not None:
                try:
                    with open(file.name, "r", encoding="utf-8", errors="ignore") as f:
                        file_content = f.read()
                except Exception as e:
                    file_content = f"[Error reading file: {e}]"

            if file_content:
                user_message = (
                    f"User question:\n{user_prompt}\n\n"
                    f"Attached file content:\n{file_content}\n"
                )
            else:
                user_message = user_prompt

            messages.append(HumanMessage(content=user_message))

            def invoke_agent():
                return agent.invoke(
                    {"messages": messages},
                    config={"callbacks": [ConsoleCallbackHandler()]}
                )

            result, usage = run_with_token_tracking(invoke_agent)
            final_response = result["messages"][-1].content + usage
            return final_response

        # Otherwise, assume logs-related → use Code 1 path
        else:
            results = fetch_logs()

            if not results or "error" in results[0]:
                return f"Could not fetch logs from DB: {results}"

            level_counts = {}
            for log in results:
                level = log.get("level", "UNKNOWN").upper()
                level_counts[level] = level_counts.get(level, 0) + 1

            summary = "\n".join([f"{level}: {count}" for level, count in level_counts.items()])
            debug_count = level_counts.get("DEBUG", 0)

            logs_str = json.dumps(results, indent=2, default=str)

            messages = [
                {
                    "role": "system",
                    "content": (
                        """
You are a highly experienced data analyst specializing in system and API log analysis.
Your task is to analyze structured log data provided to you...
(Instructions unchanged from Code 1)
"""
                    ),
                },
                {
                    "role": "user",
                    "content": (
                        f"{user_prompt}\n\n"
                        f"--- Log Summary ---\n{summary}\n\n"
                        f"Total DEBUG logs: {debug_count}\n\n"
                        f"--- Raw Logs (latest 100 rows) ---\n{logs_str}"
                    ),
                },
            ]

            def invoke_llm():
                return llm.invoke(messages, config={"callbacks": [ConsoleCallbackHandler()]})

            result, usage = run_with_token_tracking(invoke_llm)
            final_response = result.content + usage
            return final_response

    except Exception as e:
        return f"Error: {str(e)}"


# -------------------------------
# Gradio UI (Single)
# -------------------------------
chatbot_ui = gr.ChatInterface(
    fn=chat_with_agent,
    additional_inputs=[
        gr.File(
            label="Upload a file (optional)",
            file_types=[".txt", ".java", ".py", ".js", ".cpp", ".md", ".log", "*"]
        )
    ],
    title="OSIF Co-Developer",
    description="Ask about logs, coding, or upload a file. The AI will analyze and respond accordingly.",
    theme="default"
)


# -------------------------------
# Launch App
# -------------------------------
if __name__ == "__main__":
    chatbot_ui.launch(debug=False)
