import os
import shutil
import zipfile
import json
import logging
from base64 import b64decode
import random
import string
import tempfile
from Crypto.Cipher import AES

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def unpad(data):
    padding_length = data[-1]
    return data[:-padding_length]

def decrypt(data, key):
    try:
        cipher = AES.new(b64decode(key), AES.MODE_ECB)
        decrypted_data = cipher.decrypt(b64decode(data))
        decrypted_data = unpad(decrypted_data)
        return decrypted_data.decode()
    except Exception as e:
        logger.error(f"Error during decryption: {e}")
        raise ValueError(f"Error during decryption: {e}")

def mock_openai_client(model_instance_name):
    class MockClient:
        def invoke(self, messages):
            prompt_and_raml = messages[0]['content']
            raml_content = prompt_and_raml.split('\n\n', 1)[-1]
            endpoints = extract_endpoints_from_raml(raml_content)
            payloads = generate_payloads_for_endpoints(endpoints)
            return type('obj', (object,), {'content': json.dumps(payloads)})
    return MockClient()

def extract_endpoints_from_raml(raml_content):
    endpoints = []
    for line in raml_content.splitlines():
        if line.strip().startswith('/'):
            endpoints.append(line.strip())
    return endpoints

def generate_payloads_for_endpoints(endpoints):
    payloads = {}
    for endpoint in endpoints:
        field_count = random.randint(2, 5)
        payloads[endpoint] = {
            f"field{i+1}": generate_random_value() for i in range(field_count)
        }
    return payloads

def generate_random_value():
    char_set = string.ascii_letters + string.digits
    value_type = random.choice(['text', 'int', 'float', 'bool'])
    if value_type == 'text':
        return ''.join(random.choices(char_set, k=random.randint(5, 12)))
    elif value_type == 'int':
        return random.randint(1, 10000)
    elif value_type == 'float':
        return round(random.uniform(1.0, 1000.0), 2)
    elif value_type == 'bool':
        return random.choice([True, False])
    return ''.join(random.choices(char_set, k=8))

def unzip_raml(zip_bytes):
    try:
        temp_dir = tempfile.mkdtemp(prefix="raml_")
        zip_path = os.path.join(temp_dir, "uploaded.zip")
        with open(zip_path, "wb") as f:
            f.write(zip_bytes)

        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(temp_dir)

        return temp_dir
    except Exception as e:
        logger.error(f"Error unzipping RAML file: {e}")
        raise ValueError(f"Error unzipping RAML file: {e}")

def find_main_raml_file(base_dir):
    try:
        for root, _, files in os.walk(base_dir):
            for file in files:
                if file.endswith(".raml"):
                    full_path = os.path.join(root, file)
                    with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                        if "#%RAML 1.0" in f.readline():
                            return full_path
        raise FileNotFoundError("Main RAML file not found.")
    except Exception as e:
        logger.error(f"Error finding main RAML file: {e}")
        raise ValueError(f"Error finding main RAML file: {e}")

def resolve_include_path(include_path, root_dir, current_dir):
    search_dirs = [
        os.path.join(root_dir, 'examples', 'request'),
        current_dir,
        root_dir
    ]

    for dir_path in search_dirs:
        full_path = os.path.normpath(os.path.join(dir_path, include_path))
        if os.path.isfile(full_path):
            return full_path

    for base in [os.path.join(root_dir, 'examples', 'request'), root_dir]:
        for root, _, files in os.walk(base):
            for f in files:
                if f == os.path.basename(include_path):
                    return os.path.join(root, f)

    return None

def resolve_includes_in_raml(file_path, root_dir):
    resolved_lines = []
    current_dir = os.path.dirname(file_path)

    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
        for line in file:
            if "!include" in line:
                parts = line.strip().split("!include")
                prefix = parts[0].strip()
                include_path = parts[1].strip()
                include_file = resolve_include_path(include_path, root_dir, current_dir)
                if include_file and os.path.exists(include_file):
                    with open(include_file, 'r', encoding='utf-8', errors='ignore') as inc_file:
                        resolved_lines.append(f"{prefix} |\n")
                        for inc_line in inc_file.read().splitlines():
                            resolved_lines.append(f"  {inc_line}")
                else:
                    resolved_lines.append(f"{line.strip()}  # Include not found")
            else:
                resolved_lines.append(line.rstrip())

    return "\n".join(resolved_lines)

def analyze_raml_with_openai(client, prompt, resolved_raml_content):
    try:
        full_prompt = f"{prompt}\n\n{resolved_raml_content}"
        response = client.invoke([{"content": full_prompt}])
        return response.content
    except Exception as e:
        logger.error(f"Error analyzing RAML with OpenAI: {e}")
        raise ValueError(f"Error analyzing RAML with OpenAI: {e}")

def lambda_handler(event, context):
    logger.info("Lambda invoked.")
    try:
        if 'body' not in event or not event.get('isBase64Encoded', False):
            raise ValueError("File content is missing or not base64-encoded.")

        zip_bytes = b64decode(event['body'])
        headers = event.get('headers', {})

        prompt = (
            headers.get('prompt') or
            headers.get('Prompt') or
            os.environ.get('DEFAULT_RAML_PROMPT', 'Analyze this RAML and generate test payloads.')
        )

        model_instance_name = (
            headers.get('model_instance_name') or
            headers.get('Model_Instance_Name') or
            os.environ.get('DEFAULT_MODEL_INSTANCE_NAME', 'default-model')
        )

        extracted_dir = unzip_raml(zip_bytes)
        main_raml_file = find_main_raml_file(extracted_dir)
        resolved_raml = resolve_includes_in_raml(main_raml_file, extracted_dir)

        client = mock_openai_client(model_instance_name)
        final_output = analyze_raml_with_openai(client, prompt, resolved_raml)

        return {
            "statusCode": 200,
            "headers": {"Content-Type": "application/json"},
            "body": final_output
        }

    except Exception as e:
        logger.error(f"Error during execution: {e}")
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }


{
    "/heartbeat:": {
        "field1": 897.64,
        "field2": 195.55,
        "field3": 651,
        "field4": false,
        "field5": 415.63
    },
    "/salesreturns:": {
        "field1": "2wP79j",
        "field2": false,
        "field3": true,
        "field4": true
    }
}
