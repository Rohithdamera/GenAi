i am getting this response for the below code, but it is there in data base , i think it is not fetching from data base , give me full updated code according to my requirement 

response:-

how many debug logs are there

There are no DEBUG logs present. Total DEBUG logs: 0.

--- Token Usage ---
Total Tokens: 92
Prompt Tokens: 78
Completion Tokens: 14
Total Cost (USD): $0.001200

how many logs are there

There are no DEBUG logs in the summary provided.

--- Token Usage ---
Total Tokens: 87
Prompt Tokens: 77
Completion Tokens: 10
Total Cost (USD): $0.001070





code:-

import gradio as gr
import mysql.connector
import json
from langchain_openai import AzureChatOpenAI
from langchain.callbacks import get_openai_callback
from langchain_core.tracers.stdout import ConsoleCallbackHandler

# -------------------------------
# Configure Azure OpenAI
# -------------------------------
llm = AzureChatOpenAI(
    deployment_name="gpt-4_complex_conversions",
    azure_endpoint="https://testopenaiassets.openai.azure.com",
    openai_api_key="",
    openai_api_version="2025-01-01-preview"
)

# -------------------------------
# Configure MySQL
# -------------------------------
config = {
    "host": "localhost",
    "user": "root",
    "password": "Admin",
    "database": "test_data"
}

def fetch_logs():
    """Fetch logs or API performance data from MySQL."""
    conn = mysql.connector.connect(**config)
    cursor = conn.cursor(dictionary=True)

    try:
        cursor.execute("SELECT * FROM api_logs LIMIT 50")  # Adjust table name if needed
        results = cursor.fetchall()
    except Exception as e:
        results = [{"error": str(e)}]

    cursor.close()
    conn.close()
    return results

# -------------------------------
# Chat Function
# -------------------------------
def chat_with_agent(user_prompt, history):
    try:
        # Fetch logs from DB
        results = fetch_logs()

        # Analyze logs before sending to LLM
        level_counts = {}
        for log in results:
            level = log.get("level", "UNKNOWN").upper()
            level_counts[level] = level_counts.get(level, 0) + 1

        summary = "\n".join([f"{level}: {count}" for level, count in level_counts.items()])
        debug_count = level_counts.get("DEBUG", 0)

        # Construct final prompt for LLM
        messages = [
            {
                "role": "system",
                "content": (
                    "You are a senior data analyst. Analyze API/system logs. "
                    "Answer questions like 'how many debugs happened' or "
                    "'what errors are present in the logs'. "
                    "Be concise and structured in your response."
                ),
            },
            {
                "role": "user",
                "content": (
                    f"{user_prompt}\n\nHere is a summary of log levels:\n{summary}\n\n"
                    f"Total DEBUG logs: {debug_count}"
                )
            },
        ]

        # Call Azure LLM with callback to track token usage
        with get_openai_callback() as cb:
            result = llm.invoke(messages, config={"callbacks": [ConsoleCallbackHandler()]})
            final_response = result.content

            # Append token usage details
            final_response += "\n\n--- Token Usage ---"
            final_response += f"\nTotal Tokens: {cb.total_tokens}"
            final_response += f"\nPrompt Tokens: {cb.prompt_tokens}"
            final_response += f"\nCompletion Tokens: {cb.completion_tokens}"
            final_response += f"\nTotal Cost (USD): ${format(cb.total_cost, '.6f')}"

        return final_response

    except Exception as e:
        return f" Error: {str(e)}"


# -------------------------------
# Gradio UI
# -------------------------------
chatbot_ui = gr.ChatInterface(
    fn=chat_with_agent,
    title="OSIF Co-Developer",
    description="Query system/API logs with natural language",
    theme="default"
)

# Launch UI
if __name__ == "__main__":
    chatbot_ui.launch(debug=False)
