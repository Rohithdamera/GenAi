import os
import json
import zipfile
import shutil
import logging
from base64 import b64decode
from langchain_community.chat_models import AzureChatOpenAI
from langchain.schema import HumanMessage

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def unzip_raml(zip_data, extract_dir="/tmp/temp_raml"):
    if os.path.exists(extract_dir):
        shutil.rmtree(extract_dir)
    os.makedirs(extract_dir, exist_ok=True)

    with zipfile.ZipFile(zip_data, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)

    return extract_dir

def find_main_raml_file(base_dir):
    for root, _, files in os.walk(base_dir):
        for file in files:
            if file.endswith(".raml"):
                full_path = os.path.join(root, file)
                with open(full_path, 'r', encoding='utf-8', errors='ignore') as raml_file:
                    first_line = raml_file.readline()
                    if "#%RAML 1.0" in first_line:
                        return full_path
    raise FileNotFoundError("No main RAML file found.")

def resolve_includes_in_raml(file_path, root_dir):
    resolved_lines = []
    current_dir = os.path.dirname(file_path)

    def resolve_include_path(include_path):
        paths = [
            os.path.normpath(os.path.join(current_dir, include_path)),
            os.path.normpath(os.path.join(root_dir, include_path))
        ]
        for p in paths:
            if os.path.isfile(p):
                return p
        for root, _, files in os.walk(root_dir):
            for f in files:
                if f == os.path.basename(include_path):
                    return os.path.join(root, f)
        return None

    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
        for line in file:
            if "!include" in line:
                parts = line.strip().split("!include")
                prefix = parts[0].strip()
                include_path = parts[1].strip()

                include_file = resolve_include_path(include_path)
                if include_file:
                    with open(include_file, 'r', encoding='utf-8', errors='ignore') as inc_file:
                        included_content = inc_file.read()
                        resolved_lines.append(f"{prefix} |\n")
                        for inc_line in included_content.splitlines():
                            resolved_lines.append(f"  {inc_line}")
                else:
                    resolved_lines.append(f"{line.strip()}  # Include not found")
            else:
                resolved_lines.append(line.rstrip())

    return "\n".join(resolved_lines)

def find_example_requests(root_dir):
    example_requests = {}
    examples_request_path = os.path.join(root_dir, "examples", "request")

    if os.path.exists(examples_request_path):
        for root, _, files in os.walk(examples_request_path):
            for file in files:
                if file.endswith(".json"):
                    endpoint_name = os.path.splitext(file)[0].lower()
                    with open(os.path.join(root, file), 'r', encoding='utf-8', errors='ignore') as f:
                        example_requests[endpoint_name] = json.load(f)
    return example_requests

def get_openai_client(model_instance_name):
    try:
        aes_key_base64 = os.environ['AES_KEY']
        encrypted_api_base = os.environ['ENCRYPTED_API_BASE']
        encrypted_api_key = os.environ['ENCRYPTED_API_KEY']
        api_version = os.environ['AZURE_API_VERSION']

        decrypted_api_base = decrypt(encrypted_api_base, aes_key_base64)
        decrypted_api_key = decrypt(encrypted_api_key, aes_key_base64)

        if not decrypted_api_base.endswith('/'):
            decrypted_api_base += '/'

        return AzureChatOpenAI(
            deployment_name=model_instance_name,
            openai_api_base=decrypted_api_base,
            openai_api_key=decrypted_api_key,
            openai_api_version=api_version
        )
    except Exception as e:
        logger.error(f"Error initializing OpenAI client: {e}")
        raise ValueError(f"Error initializing OpenAI client: {e}")

def lambda_handler(event, context):
    logger.info(f"Received event: {json.dumps(event)}")

    try:
        if 'body' not in event or not event.get('isBase64Encoded', False):
            raise ValueError("File content missing or not base64-encoded.")
        
        file_content = b64decode(event['body'])

        zip_path = "/tmp/uploaded.zip"
        with open(zip_path, "wb") as temp_zip_file:
            temp_zip_file.write(file_content)

        extracted_dir = unzip_raml(zip_path)
        main_raml_file = find_main_raml_file(extracted_dir)
        logger.info(f"Main RAML File Found: {main_raml_file}")

        resolved_raml = resolve_includes_in_raml(main_raml_file, extracted_dir)
        example_requests = find_example_requests(extracted_dir)

        if not example_requests:
            raise ValueError("No example request payloads found inside examples/request.")

        model_instance_name = event.get('headers', {}).get('model_instance_name')
        if not model_instance_name:
            raise ValueError("'model_instance_name' missing in headers.")
        
        client = get_openai_client(model_instance_name)

        # Correct way: Take headers sent by user (no hardcoded defaults)
        headers = {}
        incoming_headers = event.get('headers', {})
        expected_headers = ["client_id", "client_secret", "correlationId"]

        for key in expected_headers:
            if key in incoming_headers:
                headers[key] = incoming_headers[key]

        response_lines = ["Generated Payloads:\n"]

        for endpoint, payload in example_requests.items():
            response_lines.append(f"### Endpoint: /{endpoint} (POST)")
            response_lines.append("**Input Payload:**")
            response_lines.append("```json")
            response_lines.append(json.dumps(payload, indent=2))
            response_lines.append("```")
            if headers:
                response_lines.append("**Headers:**")
                for k, v in headers.items():
                    response_lines.append(f"- {k}: \"{v}\"")
            response_lines.append("")  # Blank line between endpoints

        final_response = "\n".join(response_lines)

        return {
            "statusCode": 200,
            "headers": {"Content-Type": "application/json"},
            "body": json.dumps({"generated_payloads": final_response})
        }

    except Exception as e:
        logger.error(f"Error: {e}")
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }

def decrypt(data, key):
    from Crypto.Cipher import AES
    def unpad(data):
        padding_length = data[-1]
        return data[:-padding_length]

    cipher = AES.new(b64decode(key), AES.MODE_ECB)
    decrypted_data = cipher.decrypt(b64decode(data))
    decrypted_data = unpad(decrypted_data)
    return decrypted_data.decode()
