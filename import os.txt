import gradio as gr
from langgraph.prebuilt import create_react_agent
from langchain_openai import AzureChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langchain.callbacks.tracers import ConsoleCallbackHandler
from langchain_community.callbacks import get_openai_callback
import os

# Create a local reference to remote llm model
llm = AzureChatOpenAI(
    deployment_name="gpt-4_complex_conversions",
    azure_endpoint="https://testopenaiassets.openai.azure.com",
    openai_api_key="",  # put your key
    openai_api_version="2025-01-01-preview",
)

# Optional: tools if you want
agent = create_react_agent(
    model=llm,
    tools=[],
    verbose=True
)

# Define the chatbot function
def chat_with_agent(message, history, file=None):
    messages = []

    # ✅ Fix: history can be None
    if history is not None:
        for user_msg, bot_msg in history:
            messages.append(HumanMessage(content=user_msg))
            messages.append(AIMessage(content=bot_msg))

    # If a file is uploaded, read its contents
    file_content = ""
    if file is not None:
        try:
            with open(file.name, "r", encoding="utf-8", errors="ignore") as f:
                file_content = f.read()
        except Exception as e:
            file_content = f"[Error reading file: {e}]"

    # Construct the final user message
    if file_content:
        user_message = (
            f"{message}\n\n--- File Content Start ---\n{file_content}\n--- File Content End ---"
        )
    else:
        user_message = message

    messages.append(HumanMessage(content=user_message))

    try:
        with get_openai_callback() as cb:
            result = agent.invoke(
                {"messages": messages},
                config={"callbacks": [ConsoleCallbackHandler()]}
            )
            final_response = result["messages"][-1].content

            # Token usage info
            final_response += "\n\n--- Token Usage ---"
            final_response += f"\nTotal Tokens: {cb.total_tokens}"
            final_response += f"\nPrompt Tokens: {cb.prompt_tokens}"
            final_response += f"\nCompletion Tokens: {cb.completion_tokens}"
            final_response += f"\nTotal Cost (USD): ${format(cb.total_cost, '.6f')}"
    finally:
        print("Interaction completed")

    return final_response

# ✅ Keep ChatInterface UI but add file upload
chatbot_ui = gr.ChatInterface(
    fn=chat_with_agent,
    additional_inputs=[
        gr.File(
            label="Upload a file (optional)",
            file_types=[".txt", ".java", ".py", ".js", ".cpp", ".md", "*"]
        )
    ],
    title="OSIF Co-Developer",
    description="Your co-developer for OSIF development",
    theme="default"
)

# Launch the app
chatbot_ui.launch(debug=False)