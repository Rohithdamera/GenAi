import json
import requests
from langchain.chat_models import AzureChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.agents import Tool, initialize_agent
from langchain.memory import ConversationBufferMemory

# === MCP Server Configuration ===
MCP_URL = "https://your.mcp.server.url"  # ðŸ” Replace with actual server URL

MCP_PAYLOAD = {
    "method": "tools/call",
    "params": {
        "name": "get-vendors",
        "arguments": {}
    }
}

# === Global store for response ===
mcp_raw_data = ""

# === Azure OpenAI Config ===
def get_openai_client():
    return AzureChatOpenAI(
        azure_endpoint="https://testopenaiassets.openai.azure.com",
        deployment_name="Fourth_Chatbot",
        openai_api_key="",  # ðŸ”‘ Put your key here
        openai_api_version="2024-08-01-preview",
        openai_api_type="azure",
        temperature=0.5,
        max_tokens=1500,
        model_kwargs={"top_p": 0.9}
    )

# === Tool 1: Fetch MCP data via POST (like Postman) ===
def fetch_mcp_data(_: str) -> str:
    global mcp_raw_data

    try:
        print("â³ Fetching from MCP server... Please wait (may take up to 3 minutes)...")

        headers = {
            "Content-Type": "application/json"
        }

        response = requests.post(
            MCP_URL,
            json=MCP_PAYLOAD,
            headers=headers,
            timeout=180  # wait 3 mins max
        )

        if response.status_code != 200:
            return f"[ERROR] MCP responded with status code {response.status_code}: {response.text}"

        mcp_raw_data = json.dumps(response.json(), indent=2)
        return "[SUCCESS] MCP data fetched successfully and stored."
    except requests.exceptions.Timeout:
        return "[ERROR] MCP server timeout (took more than 3 minutes)."
    except Exception as e:
        return f"[ERROR] MCP fetch failed: {str(e)}"

# === Tool 2: Summarize the MCP data ===
def summarize_mcp_data(_: str) -> str:
    global mcp_raw_data
    if not mcp_raw_data:
        return "[SKIP] No data available. Run 'FetchMCPData' first."

    try:
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=100
        )
        chunks = splitter.split_text(mcp_raw_data)

        prompt = PromptTemplate(
            input_variables=["chunk"],
            template="""
You are a helpful assistant. Summarize this JSON chunk about vendor data in plain language.

Focus on:
- Key vendors
- Important fields or settings
- Any data patterns

{chunk}
"""
        )

        chain = LLMChain(llm=get_openai_client(), prompt=prompt)

        summaries = [chain.run({"chunk": chunk}) for chunk in chunks]
        return "\n\n".join(summaries)

    except Exception as e:
        return f"[ERROR] Summarization failed: {str(e)}"

# === LangChain Agent Setup ===
def run_agent():
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

    tools = [
        Tool(
            name="FetchMCPData",
            func=fetch_mcp_data,
            description="Connect to MCP server and fetch vendor data (just like Postman)."
        ),
        Tool(
            name="SummarizeMCPData",
            func=summarize_mcp_data,
            description="Summarize the MCP vendor data in clear language."
        )
    ]

    agent = initialize_agent(
        tools=tools,
        llm=get_openai_client(),
        agent_type="openai-functions",
        memory=memory,
        verbose=True
    )

    return agent

# === MAIN ===
if __name__ == "__main__":
    print("ðŸ”§ Initializing MCP LangChain Agent...\n")
    agent = run_agent()

    print("ðŸš€ Starting: Fetch and summarize MCP vendor data...\n")
    result = agent.invoke("Fetch MCP data and summarize it.")
    print("\nâœ… FINAL OUTPUT:\n")
    print(result)
